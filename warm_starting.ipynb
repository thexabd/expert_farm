{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/farm-gym/farm-gym\n",
      "  Cloning https://github.com/farm-gym/farm-gym to c:\\users\\abdul\\appdata\\local\\temp\\pip-req-build-lbja58xu\n",
      "  Resolved https://github.com/farm-gym/farm-gym to commit 9458f2944272b64850a43382f5e0c719f7bcef3f\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: gymnasium in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from farmgym==1.23.3) (0.29.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from farmgym==1.23.3) (1.23.5)\n",
      "Requirement already satisfied: pillow in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from farmgym==1.23.3) (10.1.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from farmgym==1.23.3) (1.10.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from farmgym==1.23.3) (6.0.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from farmgym==1.23.3) (2.0.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from farmgym==1.23.3) (3.7.1)\n",
      "Requirement already satisfied: mpld3 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from farmgym==1.23.3) (0.5.10)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from farmgym==1.23.3) (4.9.0.80)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from farmgym==1.23.3) (2.15.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gymnasium->farmgym==1.23.3) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gymnasium->farmgym==1.23.3) (4.5.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gymnasium->farmgym==1.23.3) (0.0.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->farmgym==1.23.3) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->farmgym==1.23.3) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->farmgym==1.23.3) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->farmgym==1.23.3) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->farmgym==1.23.3) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->farmgym==1.23.3) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->farmgym==1.23.3) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mpld3->farmgym==1.23.3) (3.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas->farmgym==1.23.3) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas->farmgym==1.23.3) (2023.3)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard->farmgym==1.23.3) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard->farmgym==1.23.3) (1.54.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard->farmgym==1.23.3) (2.19.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard->farmgym==1.23.3) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard->farmgym==1.23.3) (3.4.3)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard->farmgym==1.23.3) (4.23.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard->farmgym==1.23.3) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from tensorboard->farmgym==1.23.3) (65.5.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard->farmgym==1.23.3) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard->farmgym==1.23.3) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard->farmgym==1.23.3) (2.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard->farmgym==1.23.3) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard->farmgym==1.23.3) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard->farmgym==1.23.3) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard->farmgym==1.23.3) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->farmgym==1.23.3) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard->farmgym==1.23.3) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard->farmgym==1.23.3) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard->farmgym==1.23.3) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from werkzeug>=1.0.1->tensorboard->farmgym==1.23.3) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->farmgym==1.23.3) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\abdul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->farmgym==1.23.3) (3.2.2)\n",
      "Successfully installed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/farm-gym/farm-gym 'C:\\Users\\abdul\\AppData\\Local\\Temp\\pip-req-build-lbja58xu'\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/farm-gym/farm-gym\n",
    "print(\"Successfully installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original observation : \n",
      "[{'Free': {'Field-0': {'Weather-0': {'day#int365': 1}}}}, {'Free': {'Field-0': {'Weather-0': {'air_temperature': {'max#°C': [3.8], 'mean#°C': [1.1], 'min#°C': [-1.9]}}}}}, {'Free': {'Field-0': {'Weather-0': {'consecutive_dry#day': [1]}}}}, {'Free': {'Field-0': {'Soil-0': {'available_Water#L': {'[(0, 0)]': [125.0]}}}}}, {'Free': {'Field-0': {'Soil-0': {'microlife_health_index#%': {'[(0, 0)]': [75.0]}}}}}, {'Free': {'Field-0': {'Plant-0': {'stage': {'[(0, 0)]': 1}}}}}, {'Free': {'Field-0': {'Plant-0': {'population#nb': {'[(0, 0)]': [1.0]}}}}}, {'Free': {'Field-0': {'Plant-0': {'size#cm': {'[(0, 0)]': [0]}}}}}, {'Free': {'Field-0': {'Plant-0': {'fruits_per_plant#nb': {'[(0, 0)]': [0]}}}}}, {'Free': {'Field-0': {'Plant-0': {'fruit_weight#g': {'[(0, 0)]': [0]}}}}}, {'Free': {'Field-0': {'Pollinators-0': {'occurrence#bin': {'[(0, 0)]': 1}}}}}]\n",
      "\n",
      "Wrapped observation : \n",
      "[1, 3.8, 1.1, -1.9, 1, 125.0, 75.0, 1, 1.0, 0, 0, 0, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialise the environment and add wrappers\n",
    "\n",
    "from farmgym_games.game_builder.utils_sb3 import farmgym_to_gym_observations_flattened, wrapper\n",
    "from farmgym_games.game_catalogue.farm0.farm import env as Farm0\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "env = Farm0()\n",
    "orignal_obs, _  = env.reset()\n",
    "print(f\"Original observation : \\n{orignal_obs}\\n\")\n",
    "\n",
    "# Wrap to change observation and action spaces and the step function\n",
    "env.farmgym_to_gym_observations = farmgym_to_gym_observations_flattened\n",
    "env = wrapper(env)\n",
    "obs, _ = env.reset()\n",
    "print(f\"Wrapped observation : \\n{obs}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expert_policy(obs):\n",
    "\n",
    "    action = 0\n",
    "\n",
    "    if obs[0] == 1:\n",
    "        action = 6\n",
    "    if obs[5] < 124:\n",
    "        action = 1\n",
    "    if obs[5] < 123:\n",
    "        action = 2\n",
    "    if obs[5] < 122:\n",
    "        action = 3\n",
    "    if obs[5] < 121:\n",
    "        action = 4\n",
    "    if obs[5] < 120:\n",
    "        action = 5\n",
    "    if obs[7] == 9:\n",
    "        action = 7\n",
    "    else:\n",
    "        action = 6\n",
    "\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_returns(rewards, gamma=0.99):\n",
    "    \"\"\"\n",
    "    Compute discounted cumulative rewards (returns) for an episode.\n",
    "    \"\"\"\n",
    "    returns = []\n",
    "    G = 0\n",
    "    for r in reversed(rewards):\n",
    "        G = r + gamma * G\n",
    "        returns.insert(0, G)\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expert dataset\n",
    "\n",
    "from torch.utils.data.dataset import Dataset, random_split\n",
    "\n",
    "class ExpertDataSetActor(Dataset):\n",
    "    def __init__(self, expert_observations, expert_actions):\n",
    "        self.observations = expert_observations\n",
    "        self.actions = expert_actions\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.observations[index], self.actions[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.observations)\n",
    "    \n",
    "class ExpertDataSetCritic(Dataset):\n",
    "    def __init__(self, expert_observations, expert_actions, expert_returns):\n",
    "        self.observations = expert_observations\n",
    "        self.actions = expert_actions\n",
    "        self.returns = expert_returns\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.observations[index], self.actions[index], self.returns[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "# Function to generate offline data\n",
    "\n",
    "def generate_offline_data(num_interactions, gamma=0.99):\n",
    "    expert_observations = []\n",
    "    expert_actions = []\n",
    "    expert_returns = []\n",
    "\n",
    "    interaction_count = 0\n",
    "    while interaction_count < num_interactions:\n",
    "        obs, _ = env.reset()\n",
    "        episode_rewards = []\n",
    "        episode_observations = []\n",
    "        episode_actions = []\n",
    "        \n",
    "        done = False\n",
    "        while not done and interaction_count < num_interactions:\n",
    "            action = expert_policy(obs)\n",
    "            next_obs, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            \n",
    "            episode_observations.append(obs)\n",
    "            episode_actions.append(action)\n",
    "            episode_rewards.append(reward)\n",
    "\n",
    "            obs = next_obs\n",
    "            interaction_count += 1\n",
    "\n",
    "        # Compute returns for the episode\n",
    "        episode_returns = compute_returns(episode_rewards, gamma)\n",
    "        \n",
    "        # Append episode data to expert data\n",
    "        expert_observations.extend(episode_observations)\n",
    "        expert_actions.extend(episode_actions)\n",
    "        expert_returns.extend(episode_returns)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    expert_observations = np.array(expert_observations)\n",
    "    expert_actions = np.array(expert_actions)\n",
    "    expert_returns = np.array(expert_returns)\n",
    "\n",
    "    # Save data to compressed file\n",
    "    np.savez_compressed(\n",
    "        \"WS_data_{}\".format(num_interactions),\n",
    "        expert_observations=expert_observations,\n",
    "        expert_actions=expert_actions,\n",
    "        expert_returns=expert_returns\n",
    "    )\n",
    "\n",
    "    return expert_observations, expert_actions, expert_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_expert_dataset:  80000\n",
      "test_expert_dataset:  20000\n"
     ]
    }
   ],
   "source": [
    "expert_observations, expert_actions, expert_returns = generate_offline_data(num_interactions=100000)\n",
    "\n",
    "expert_dataset_actor = ExpertDataSetActor(expert_observations, expert_actions)\n",
    "expert_dataset_critic = ExpertDataSetCritic(expert_observations, expert_actions, expert_returns)\n",
    "\n",
    "train_size = int(0.8 * len(expert_dataset_actor))\n",
    "\n",
    "test_size = len(expert_dataset_actor) - train_size\n",
    "\n",
    "train_expert_dataset_actor, test_expert_dataset_actor = random_split(\n",
    "    expert_dataset_actor, [train_size, test_size]\n",
    ")\n",
    "train_expert_dataset_critic, test_expert_dataset_critic = random_split(\n",
    "    expert_dataset_critic, [train_size, test_size]\n",
    ")\n",
    "\n",
    "print(\"train_expert_dataset: \", len(train_expert_dataset_actor))\n",
    "print(\"test_expert_dataset: \", len(test_expert_dataset_actor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(expert_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "def pretrain_agent(student, batch_size=64, epochs=20, scheduler_gamma=0.7, learning_rate=0.001, log_interval=100, no_cuda=True, seed=1, test_batch_size=64):\n",
    "    \n",
    "    use_cuda = not no_cuda and th.cuda.is_available()\n",
    "    th.manual_seed(seed)\n",
    "    device = th.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    kwargs = {\"num_workers\": 1, \"pin_memory\": True} if use_cuda else {}\n",
    "\n",
    "    criterion1 = nn.CrossEntropyLoss()\n",
    "    criterion2 = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Extract initial policy\n",
    "    model = student.policy.to(device)\n",
    "\n",
    "    def train_actor(model, device, train_loader, optimizer):\n",
    "        model.train()\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Retrieve the logits for A2C/PPO when using discrete actions\n",
    "            dist = model.get_distribution(data)\n",
    "            action_prediction = dist.distribution.logits\n",
    "            target = target.long()\n",
    "\n",
    "            loss = criterion1(action_prediction, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print(\n",
    "                    \"Actor Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                        epoch,\n",
    "                        batch_idx * len(data),\n",
    "                        len(train_loader.dataset),\n",
    "                        100.0 * batch_idx / len(train_loader),\n",
    "                        loss.item(),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    def train_critic(model, device, train_loader, optimizer):\n",
    "        model.train()\n",
    "\n",
    "        for batch_idx, (obs, action, target) in enumerate(train_loader):\n",
    "            obs, action, target = obs.to(device), action.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Retrieve the logits for A2C/PPO when using discrete actions\n",
    "            # model.evaluate_actions(obs, actions)\n",
    "            value, _, _ = model.evaluate_actions(obs, action)\n",
    "            target = target.float()\n",
    "            value = value.squeeze()\n",
    "\n",
    "            loss = criterion2(value, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print(\n",
    "                    \"Critic Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                        epoch,\n",
    "                        batch_idx * len(obs),\n",
    "                        len(train_loader.dataset),\n",
    "                        100.0 * batch_idx / len(train_loader),\n",
    "                        loss.item(),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    def test_actor(model, device, test_loader):\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        with th.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                # Retrieve the logits for A2C/PPO when using discrete actions\n",
    "                dist = model.get_distribution(data)\n",
    "                action_prediction = dist.distribution.logits\n",
    "                target = target.long()\n",
    "\n",
    "                test_loss = criterion1(action_prediction, target)\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print(f\"Test set actor: Average loss: {test_loss:.4f}\")\n",
    "\n",
    "    def test_critic(model, device, test_loader):\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        with th.no_grad():\n",
    "            for obs, action, target in test_loader:\n",
    "                obs, action, target = obs.to(device), action.to(device), target.to(device)\n",
    "\n",
    "                # Retrieve the logits for A2C/PPO when using discrete actions\n",
    "                value, _, _ = model.evaluate_actions(obs, action)\n",
    "                target = target.float()\n",
    "                value = value.squeeze()\n",
    "\n",
    "                test_loss = criterion2(value, target)\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print(f\"Test set critic: Average loss: {test_loss:.4f}\")\n",
    "\n",
    "    # Here, we use PyTorch `DataLoader` to our load previously created `ExpertDataset` for training\n",
    "    # and testing\n",
    "    train_loader_actor = th.utils.data.DataLoader(\n",
    "        dataset=train_expert_dataset_actor, batch_size=batch_size, shuffle=True, **kwargs\n",
    "    )\n",
    "    train_loader_critic = th.utils.data.DataLoader(\n",
    "        dataset=train_expert_dataset_critic, batch_size=batch_size, shuffle=True, **kwargs\n",
    "    )\n",
    "    test_loader_actor = th.utils.data.DataLoader(\n",
    "        dataset=test_expert_dataset_actor,\n",
    "        batch_size=test_batch_size,\n",
    "        shuffle=True,\n",
    "        **kwargs,\n",
    "    )\n",
    "    test_loader_critic = th.utils.data.DataLoader(\n",
    "        dataset=test_expert_dataset_critic,\n",
    "        batch_size=test_batch_size,\n",
    "        shuffle=True,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    # Define an Optimizer and a learning rate schedule.\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=learning_rate)\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=scheduler_gamma)\n",
    "\n",
    "    # Now we are finally ready to train the policy model.\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_actor(model, device, train_loader_actor, optimizer)\n",
    "        train_critic(model, device, train_loader_critic, optimizer)\n",
    "        test_actor(model, device, test_loader_actor)\n",
    "        test_critic(model, device, test_loader_critic)\n",
    "        scheduler.step()\n",
    "\n",
    "    # Implant the trained policy network back into the RL student agent\n",
    "    student.policy = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "# Create agent\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "ppo_student_ws = PPO(\"MlpPolicy\", env, verbose=1, learning_rate=0.0001, n_epochs=15, tensorboard_log='ws')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor Train Epoch: 1 [0/80000 (0%)]\tLoss: 2.078982\n",
      "Actor Train Epoch: 1 [6400/80000 (8%)]\tLoss: 2.053072\n",
      "Actor Train Epoch: 1 [12800/80000 (16%)]\tLoss: 2.018398\n",
      "Actor Train Epoch: 1 [19200/80000 (24%)]\tLoss: 1.979699\n",
      "Actor Train Epoch: 1 [25600/80000 (32%)]\tLoss: 1.935532\n",
      "Actor Train Epoch: 1 [32000/80000 (40%)]\tLoss: 1.882646\n",
      "Actor Train Epoch: 1 [38400/80000 (48%)]\tLoss: 1.834934\n",
      "Actor Train Epoch: 1 [44800/80000 (56%)]\tLoss: 1.764383\n",
      "Actor Train Epoch: 1 [51200/80000 (64%)]\tLoss: 1.700629\n",
      "Actor Train Epoch: 1 [57600/80000 (72%)]\tLoss: 1.628405\n",
      "Actor Train Epoch: 1 [64000/80000 (80%)]\tLoss: 1.556096\n",
      "Actor Train Epoch: 1 [70400/80000 (88%)]\tLoss: 1.489499\n",
      "Actor Train Epoch: 1 [76800/80000 (96%)]\tLoss: 1.386213\n",
      "Critic Train Epoch: 1 [0/80000 (0%)]\tLoss: 94118.437500\n",
      "Critic Train Epoch: 1 [6400/80000 (8%)]\tLoss: 102772.820312\n",
      "Critic Train Epoch: 1 [12800/80000 (16%)]\tLoss: 95676.718750\n",
      "Critic Train Epoch: 1 [19200/80000 (24%)]\tLoss: 90663.046875\n",
      "Critic Train Epoch: 1 [25600/80000 (32%)]\tLoss: 86620.125000\n",
      "Critic Train Epoch: 1 [32000/80000 (40%)]\tLoss: 102523.796875\n",
      "Critic Train Epoch: 1 [38400/80000 (48%)]\tLoss: 92054.781250\n",
      "Critic Train Epoch: 1 [44800/80000 (56%)]\tLoss: 97220.093750\n",
      "Critic Train Epoch: 1 [51200/80000 (64%)]\tLoss: 99356.859375\n",
      "Critic Train Epoch: 1 [57600/80000 (72%)]\tLoss: 98385.031250\n",
      "Critic Train Epoch: 1 [64000/80000 (80%)]\tLoss: 96897.882812\n",
      "Critic Train Epoch: 1 [70400/80000 (88%)]\tLoss: 86584.835938\n",
      "Critic Train Epoch: 1 [76800/80000 (96%)]\tLoss: 82260.390625\n",
      "Test set actor: Average loss: 0.0001\n",
      "Test set critic: Average loss: 2.0752\n",
      "Actor Train Epoch: 2 [0/80000 (0%)]\tLoss: 1.340521\n",
      "Actor Train Epoch: 2 [6400/80000 (8%)]\tLoss: 1.282721\n",
      "Actor Train Epoch: 2 [12800/80000 (16%)]\tLoss: 1.226984\n",
      "Actor Train Epoch: 2 [19200/80000 (24%)]\tLoss: 1.150978\n",
      "Actor Train Epoch: 2 [25600/80000 (32%)]\tLoss: 1.087932\n",
      "Actor Train Epoch: 2 [32000/80000 (40%)]\tLoss: 1.055807\n",
      "Actor Train Epoch: 2 [38400/80000 (48%)]\tLoss: 0.985110\n",
      "Actor Train Epoch: 2 [44800/80000 (56%)]\tLoss: 0.891286\n",
      "Actor Train Epoch: 2 [51200/80000 (64%)]\tLoss: 0.841967\n",
      "Actor Train Epoch: 2 [57600/80000 (72%)]\tLoss: 0.776125\n",
      "Actor Train Epoch: 2 [64000/80000 (80%)]\tLoss: 0.711276\n",
      "Actor Train Epoch: 2 [70400/80000 (88%)]\tLoss: 0.673646\n",
      "Actor Train Epoch: 2 [76800/80000 (96%)]\tLoss: 0.639659\n",
      "Critic Train Epoch: 2 [0/80000 (0%)]\tLoss: 86030.875000\n",
      "Critic Train Epoch: 2 [6400/80000 (8%)]\tLoss: 85288.140625\n",
      "Critic Train Epoch: 2 [12800/80000 (16%)]\tLoss: 88831.859375\n",
      "Critic Train Epoch: 2 [19200/80000 (24%)]\tLoss: 100669.390625\n",
      "Critic Train Epoch: 2 [25600/80000 (32%)]\tLoss: 97043.390625\n",
      "Critic Train Epoch: 2 [32000/80000 (40%)]\tLoss: 89807.054688\n",
      "Critic Train Epoch: 2 [38400/80000 (48%)]\tLoss: 89720.703125\n",
      "Critic Train Epoch: 2 [44800/80000 (56%)]\tLoss: 92097.843750\n",
      "Critic Train Epoch: 2 [51200/80000 (64%)]\tLoss: 82233.117188\n",
      "Critic Train Epoch: 2 [57600/80000 (72%)]\tLoss: 95813.007812\n",
      "Critic Train Epoch: 2 [64000/80000 (80%)]\tLoss: 95523.343750\n",
      "Critic Train Epoch: 2 [70400/80000 (88%)]\tLoss: 93291.414062\n",
      "Critic Train Epoch: 2 [76800/80000 (96%)]\tLoss: 104681.578125\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 2.4433\n",
      "Actor Train Epoch: 3 [0/80000 (0%)]\tLoss: 0.595408\n",
      "Actor Train Epoch: 3 [6400/80000 (8%)]\tLoss: 0.563478\n",
      "Actor Train Epoch: 3 [12800/80000 (16%)]\tLoss: 0.564358\n",
      "Actor Train Epoch: 3 [19200/80000 (24%)]\tLoss: 0.516067\n",
      "Actor Train Epoch: 3 [25600/80000 (32%)]\tLoss: 0.516915\n",
      "Actor Train Epoch: 3 [32000/80000 (40%)]\tLoss: 0.486389\n",
      "Actor Train Epoch: 3 [38400/80000 (48%)]\tLoss: 0.459813\n",
      "Actor Train Epoch: 3 [44800/80000 (56%)]\tLoss: 0.411901\n",
      "Actor Train Epoch: 3 [51200/80000 (64%)]\tLoss: 0.370107\n",
      "Actor Train Epoch: 3 [57600/80000 (72%)]\tLoss: 0.365496\n",
      "Actor Train Epoch: 3 [64000/80000 (80%)]\tLoss: 0.340554\n",
      "Actor Train Epoch: 3 [70400/80000 (88%)]\tLoss: 0.309620\n",
      "Actor Train Epoch: 3 [76800/80000 (96%)]\tLoss: 0.339294\n",
      "Critic Train Epoch: 3 [0/80000 (0%)]\tLoss: 109212.789062\n",
      "Critic Train Epoch: 3 [6400/80000 (8%)]\tLoss: 95744.664062\n",
      "Critic Train Epoch: 3 [12800/80000 (16%)]\tLoss: 99086.875000\n",
      "Critic Train Epoch: 3 [19200/80000 (24%)]\tLoss: 97679.414062\n",
      "Critic Train Epoch: 3 [25600/80000 (32%)]\tLoss: 93530.296875\n",
      "Critic Train Epoch: 3 [32000/80000 (40%)]\tLoss: 85535.937500\n",
      "Critic Train Epoch: 3 [38400/80000 (48%)]\tLoss: 106799.781250\n",
      "Critic Train Epoch: 3 [44800/80000 (56%)]\tLoss: 100954.140625\n",
      "Critic Train Epoch: 3 [51200/80000 (64%)]\tLoss: 96198.601562\n",
      "Critic Train Epoch: 3 [57600/80000 (72%)]\tLoss: 93959.625000\n",
      "Critic Train Epoch: 3 [64000/80000 (80%)]\tLoss: 103299.960938\n",
      "Critic Train Epoch: 3 [70400/80000 (88%)]\tLoss: 100655.796875\n",
      "Critic Train Epoch: 3 [76800/80000 (96%)]\tLoss: 79794.210938\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.6752\n",
      "Actor Train Epoch: 4 [0/80000 (0%)]\tLoss: 0.288040\n",
      "Actor Train Epoch: 4 [6400/80000 (8%)]\tLoss: 0.274811\n",
      "Actor Train Epoch: 4 [12800/80000 (16%)]\tLoss: 0.258444\n",
      "Actor Train Epoch: 4 [19200/80000 (24%)]\tLoss: 0.256095\n",
      "Actor Train Epoch: 4 [25600/80000 (32%)]\tLoss: 0.243810\n",
      "Actor Train Epoch: 4 [32000/80000 (40%)]\tLoss: 0.286611\n",
      "Actor Train Epoch: 4 [38400/80000 (48%)]\tLoss: 0.277670\n",
      "Actor Train Epoch: 4 [44800/80000 (56%)]\tLoss: 0.318126\n",
      "Actor Train Epoch: 4 [51200/80000 (64%)]\tLoss: 0.209368\n",
      "Actor Train Epoch: 4 [57600/80000 (72%)]\tLoss: 0.205016\n",
      "Actor Train Epoch: 4 [64000/80000 (80%)]\tLoss: 0.189364\n",
      "Actor Train Epoch: 4 [70400/80000 (88%)]\tLoss: 0.190573\n",
      "Actor Train Epoch: 4 [76800/80000 (96%)]\tLoss: 0.174381\n",
      "Critic Train Epoch: 4 [0/80000 (0%)]\tLoss: 72609.390625\n",
      "Critic Train Epoch: 4 [6400/80000 (8%)]\tLoss: 95674.804688\n",
      "Critic Train Epoch: 4 [12800/80000 (16%)]\tLoss: 96265.578125\n",
      "Critic Train Epoch: 4 [19200/80000 (24%)]\tLoss: 100542.781250\n",
      "Critic Train Epoch: 4 [25600/80000 (32%)]\tLoss: 86878.171875\n",
      "Critic Train Epoch: 4 [32000/80000 (40%)]\tLoss: 109486.171875\n",
      "Critic Train Epoch: 4 [38400/80000 (48%)]\tLoss: 91524.234375\n",
      "Critic Train Epoch: 4 [44800/80000 (56%)]\tLoss: 97021.750000\n",
      "Critic Train Epoch: 4 [51200/80000 (64%)]\tLoss: 92135.960938\n",
      "Critic Train Epoch: 4 [57600/80000 (72%)]\tLoss: 89636.718750\n",
      "Critic Train Epoch: 4 [64000/80000 (80%)]\tLoss: 99835.789062\n",
      "Critic Train Epoch: 4 [70400/80000 (88%)]\tLoss: 82369.312500\n",
      "Critic Train Epoch: 4 [76800/80000 (96%)]\tLoss: 95357.250000\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.7564\n",
      "Actor Train Epoch: 5 [0/80000 (0%)]\tLoss: 0.168182\n",
      "Actor Train Epoch: 5 [6400/80000 (8%)]\tLoss: 0.171557\n",
      "Actor Train Epoch: 5 [12800/80000 (16%)]\tLoss: 0.216714\n",
      "Actor Train Epoch: 5 [19200/80000 (24%)]\tLoss: 0.266435\n",
      "Actor Train Epoch: 5 [25600/80000 (32%)]\tLoss: 0.153604\n",
      "Actor Train Epoch: 5 [32000/80000 (40%)]\tLoss: 0.143448\n",
      "Actor Train Epoch: 5 [38400/80000 (48%)]\tLoss: 0.146827\n",
      "Actor Train Epoch: 5 [44800/80000 (56%)]\tLoss: 0.254866\n",
      "Actor Train Epoch: 5 [51200/80000 (64%)]\tLoss: 0.198200\n",
      "Actor Train Epoch: 5 [57600/80000 (72%)]\tLoss: 0.185766\n",
      "Actor Train Epoch: 5 [64000/80000 (80%)]\tLoss: 0.127338\n",
      "Actor Train Epoch: 5 [70400/80000 (88%)]\tLoss: 0.131512\n",
      "Actor Train Epoch: 5 [76800/80000 (96%)]\tLoss: 0.121325\n",
      "Critic Train Epoch: 5 [0/80000 (0%)]\tLoss: 104461.609375\n",
      "Critic Train Epoch: 5 [6400/80000 (8%)]\tLoss: 91798.992188\n",
      "Critic Train Epoch: 5 [12800/80000 (16%)]\tLoss: 87316.015625\n",
      "Critic Train Epoch: 5 [19200/80000 (24%)]\tLoss: 99098.562500\n",
      "Critic Train Epoch: 5 [25600/80000 (32%)]\tLoss: 89482.390625\n",
      "Critic Train Epoch: 5 [32000/80000 (40%)]\tLoss: 101115.976562\n",
      "Critic Train Epoch: 5 [38400/80000 (48%)]\tLoss: 90971.335938\n",
      "Critic Train Epoch: 5 [44800/80000 (56%)]\tLoss: 92068.179688\n",
      "Critic Train Epoch: 5 [51200/80000 (64%)]\tLoss: 94266.343750\n",
      "Critic Train Epoch: 5 [57600/80000 (72%)]\tLoss: 103830.960938\n",
      "Critic Train Epoch: 5 [64000/80000 (80%)]\tLoss: 103920.593750\n",
      "Critic Train Epoch: 5 [70400/80000 (88%)]\tLoss: 82942.906250\n",
      "Critic Train Epoch: 5 [76800/80000 (96%)]\tLoss: 87473.609375\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.5854\n",
      "Actor Train Epoch: 6 [0/80000 (0%)]\tLoss: 0.123720\n",
      "Actor Train Epoch: 6 [6400/80000 (8%)]\tLoss: 0.171550\n",
      "Actor Train Epoch: 6 [12800/80000 (16%)]\tLoss: 0.112704\n",
      "Actor Train Epoch: 6 [19200/80000 (24%)]\tLoss: 0.168500\n",
      "Actor Train Epoch: 6 [25600/80000 (32%)]\tLoss: 0.172529\n",
      "Actor Train Epoch: 6 [32000/80000 (40%)]\tLoss: 0.105947\n",
      "Actor Train Epoch: 6 [38400/80000 (48%)]\tLoss: 0.105156\n",
      "Actor Train Epoch: 6 [44800/80000 (56%)]\tLoss: 0.104380\n",
      "Actor Train Epoch: 6 [51200/80000 (64%)]\tLoss: 0.103761\n",
      "Actor Train Epoch: 6 [57600/80000 (72%)]\tLoss: 0.097603\n",
      "Actor Train Epoch: 6 [64000/80000 (80%)]\tLoss: 0.100853\n",
      "Actor Train Epoch: 6 [70400/80000 (88%)]\tLoss: 0.094823\n",
      "Actor Train Epoch: 6 [76800/80000 (96%)]\tLoss: 0.098250\n",
      "Critic Train Epoch: 6 [0/80000 (0%)]\tLoss: 87747.593750\n",
      "Critic Train Epoch: 6 [6400/80000 (8%)]\tLoss: 89943.335938\n",
      "Critic Train Epoch: 6 [12800/80000 (16%)]\tLoss: 87600.500000\n",
      "Critic Train Epoch: 6 [19200/80000 (24%)]\tLoss: 85827.664062\n",
      "Critic Train Epoch: 6 [25600/80000 (32%)]\tLoss: 86699.742188\n",
      "Critic Train Epoch: 6 [32000/80000 (40%)]\tLoss: 86928.953125\n",
      "Critic Train Epoch: 6 [38400/80000 (48%)]\tLoss: 109168.921875\n",
      "Critic Train Epoch: 6 [44800/80000 (56%)]\tLoss: 99491.476562\n",
      "Critic Train Epoch: 6 [51200/80000 (64%)]\tLoss: 100868.929688\n",
      "Critic Train Epoch: 6 [57600/80000 (72%)]\tLoss: 108480.437500\n",
      "Critic Train Epoch: 6 [64000/80000 (80%)]\tLoss: 98695.203125\n",
      "Critic Train Epoch: 6 [70400/80000 (88%)]\tLoss: 112906.984375\n",
      "Critic Train Epoch: 6 [76800/80000 (96%)]\tLoss: 99200.437500\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.9894\n",
      "Actor Train Epoch: 7 [0/80000 (0%)]\tLoss: 0.092317\n",
      "Actor Train Epoch: 7 [6400/80000 (8%)]\tLoss: 0.092465\n",
      "Actor Train Epoch: 7 [12800/80000 (16%)]\tLoss: 0.090923\n",
      "Actor Train Epoch: 7 [19200/80000 (24%)]\tLoss: 0.086950\n",
      "Actor Train Epoch: 7 [25600/80000 (32%)]\tLoss: 0.088679\n",
      "Actor Train Epoch: 7 [32000/80000 (40%)]\tLoss: 0.090356\n",
      "Actor Train Epoch: 7 [38400/80000 (48%)]\tLoss: 0.146280\n",
      "Actor Train Epoch: 7 [44800/80000 (56%)]\tLoss: 0.149190\n",
      "Actor Train Epoch: 7 [51200/80000 (64%)]\tLoss: 0.082488\n",
      "Actor Train Epoch: 7 [57600/80000 (72%)]\tLoss: 0.081630\n",
      "Actor Train Epoch: 7 [64000/80000 (80%)]\tLoss: 0.080483\n",
      "Actor Train Epoch: 7 [70400/80000 (88%)]\tLoss: 0.081903\n",
      "Actor Train Epoch: 7 [76800/80000 (96%)]\tLoss: 0.080770\n",
      "Critic Train Epoch: 7 [0/80000 (0%)]\tLoss: 101503.054688\n",
      "Critic Train Epoch: 7 [6400/80000 (8%)]\tLoss: 95858.257812\n",
      "Critic Train Epoch: 7 [12800/80000 (16%)]\tLoss: 112903.718750\n",
      "Critic Train Epoch: 7 [19200/80000 (24%)]\tLoss: 87047.773438\n",
      "Critic Train Epoch: 7 [25600/80000 (32%)]\tLoss: 90485.953125\n",
      "Critic Train Epoch: 7 [32000/80000 (40%)]\tLoss: 94334.414062\n",
      "Critic Train Epoch: 7 [38400/80000 (48%)]\tLoss: 100404.367188\n",
      "Critic Train Epoch: 7 [44800/80000 (56%)]\tLoss: 97408.648438\n",
      "Critic Train Epoch: 7 [51200/80000 (64%)]\tLoss: 87883.773438\n",
      "Critic Train Epoch: 7 [57600/80000 (72%)]\tLoss: 111583.343750\n",
      "Critic Train Epoch: 7 [64000/80000 (80%)]\tLoss: 102250.812500\n",
      "Critic Train Epoch: 7 [70400/80000 (88%)]\tLoss: 102099.757812\n",
      "Critic Train Epoch: 7 [76800/80000 (96%)]\tLoss: 95885.882812\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 2.0265\n",
      "Actor Train Epoch: 8 [0/80000 (0%)]\tLoss: 0.078897\n",
      "Actor Train Epoch: 8 [6400/80000 (8%)]\tLoss: 0.074704\n",
      "Actor Train Epoch: 8 [12800/80000 (16%)]\tLoss: 0.074293\n",
      "Actor Train Epoch: 8 [19200/80000 (24%)]\tLoss: 0.074153\n",
      "Actor Train Epoch: 8 [25600/80000 (32%)]\tLoss: 0.139743\n",
      "Actor Train Epoch: 8 [32000/80000 (40%)]\tLoss: 0.141971\n",
      "Actor Train Epoch: 8 [38400/80000 (48%)]\tLoss: 0.072548\n",
      "Actor Train Epoch: 8 [44800/80000 (56%)]\tLoss: 0.076379\n",
      "Actor Train Epoch: 8 [51200/80000 (64%)]\tLoss: 0.071031\n",
      "Actor Train Epoch: 8 [57600/80000 (72%)]\tLoss: 0.073448\n",
      "Actor Train Epoch: 8 [64000/80000 (80%)]\tLoss: 0.069479\n",
      "Actor Train Epoch: 8 [70400/80000 (88%)]\tLoss: 0.070930\n",
      "Actor Train Epoch: 8 [76800/80000 (96%)]\tLoss: 0.068238\n",
      "Critic Train Epoch: 8 [0/80000 (0%)]\tLoss: 91100.578125\n",
      "Critic Train Epoch: 8 [6400/80000 (8%)]\tLoss: 100767.062500\n",
      "Critic Train Epoch: 8 [12800/80000 (16%)]\tLoss: 97761.148438\n",
      "Critic Train Epoch: 8 [19200/80000 (24%)]\tLoss: 93556.218750\n",
      "Critic Train Epoch: 8 [25600/80000 (32%)]\tLoss: 91570.398438\n",
      "Critic Train Epoch: 8 [32000/80000 (40%)]\tLoss: 101187.539062\n",
      "Critic Train Epoch: 8 [38400/80000 (48%)]\tLoss: 105940.929688\n",
      "Critic Train Epoch: 8 [44800/80000 (56%)]\tLoss: 85156.515625\n",
      "Critic Train Epoch: 8 [51200/80000 (64%)]\tLoss: 92855.914062\n",
      "Critic Train Epoch: 8 [57600/80000 (72%)]\tLoss: 100236.984375\n",
      "Critic Train Epoch: 8 [64000/80000 (80%)]\tLoss: 109118.781250\n",
      "Critic Train Epoch: 8 [70400/80000 (88%)]\tLoss: 86579.921875\n",
      "Critic Train Epoch: 8 [76800/80000 (96%)]\tLoss: 98738.054688\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.8195\n",
      "Actor Train Epoch: 9 [0/80000 (0%)]\tLoss: 0.068918\n",
      "Actor Train Epoch: 9 [6400/80000 (8%)]\tLoss: 0.069890\n",
      "Actor Train Epoch: 9 [12800/80000 (16%)]\tLoss: 0.067511\n",
      "Actor Train Epoch: 9 [19200/80000 (24%)]\tLoss: 0.069125\n",
      "Actor Train Epoch: 9 [25600/80000 (32%)]\tLoss: 0.064841\n",
      "Actor Train Epoch: 9 [32000/80000 (40%)]\tLoss: 0.132410\n",
      "Actor Train Epoch: 9 [38400/80000 (48%)]\tLoss: 0.064939\n",
      "Actor Train Epoch: 9 [44800/80000 (56%)]\tLoss: 0.066009\n",
      "Actor Train Epoch: 9 [51200/80000 (64%)]\tLoss: 0.066102\n",
      "Actor Train Epoch: 9 [57600/80000 (72%)]\tLoss: 0.067218\n",
      "Actor Train Epoch: 9 [64000/80000 (80%)]\tLoss: 0.063263\n",
      "Actor Train Epoch: 9 [70400/80000 (88%)]\tLoss: 0.063816\n",
      "Actor Train Epoch: 9 [76800/80000 (96%)]\tLoss: 0.067071\n",
      "Critic Train Epoch: 9 [0/80000 (0%)]\tLoss: 101614.429688\n",
      "Critic Train Epoch: 9 [6400/80000 (8%)]\tLoss: 99080.382812\n",
      "Critic Train Epoch: 9 [12800/80000 (16%)]\tLoss: 103059.359375\n",
      "Critic Train Epoch: 9 [19200/80000 (24%)]\tLoss: 111857.476562\n",
      "Critic Train Epoch: 9 [25600/80000 (32%)]\tLoss: 86618.390625\n",
      "Critic Train Epoch: 9 [32000/80000 (40%)]\tLoss: 96172.351562\n",
      "Critic Train Epoch: 9 [38400/80000 (48%)]\tLoss: 84266.390625\n",
      "Critic Train Epoch: 9 [44800/80000 (56%)]\tLoss: 97336.148438\n",
      "Critic Train Epoch: 9 [51200/80000 (64%)]\tLoss: 98692.203125\n",
      "Critic Train Epoch: 9 [57600/80000 (72%)]\tLoss: 98854.226562\n",
      "Critic Train Epoch: 9 [64000/80000 (80%)]\tLoss: 98809.203125\n",
      "Critic Train Epoch: 9 [70400/80000 (88%)]\tLoss: 106140.125000\n",
      "Critic Train Epoch: 9 [76800/80000 (96%)]\tLoss: 101868.312500\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.5331\n",
      "Actor Train Epoch: 10 [0/80000 (0%)]\tLoss: 0.066156\n",
      "Actor Train Epoch: 10 [6400/80000 (8%)]\tLoss: 0.130262\n",
      "Actor Train Epoch: 10 [12800/80000 (16%)]\tLoss: 0.128193\n",
      "Actor Train Epoch: 10 [19200/80000 (24%)]\tLoss: 0.131634\n",
      "Actor Train Epoch: 10 [25600/80000 (32%)]\tLoss: 0.061359\n",
      "Actor Train Epoch: 10 [32000/80000 (40%)]\tLoss: 0.062516\n",
      "Actor Train Epoch: 10 [38400/80000 (48%)]\tLoss: 0.062487\n",
      "Actor Train Epoch: 10 [44800/80000 (56%)]\tLoss: 0.128406\n",
      "Actor Train Epoch: 10 [51200/80000 (64%)]\tLoss: 0.061540\n",
      "Actor Train Epoch: 10 [57600/80000 (72%)]\tLoss: 0.130184\n",
      "Actor Train Epoch: 10 [64000/80000 (80%)]\tLoss: 0.195889\n",
      "Actor Train Epoch: 10 [70400/80000 (88%)]\tLoss: 0.061056\n",
      "Actor Train Epoch: 10 [76800/80000 (96%)]\tLoss: 0.061035\n",
      "Critic Train Epoch: 10 [0/80000 (0%)]\tLoss: 103838.609375\n",
      "Critic Train Epoch: 10 [6400/80000 (8%)]\tLoss: 113503.031250\n",
      "Critic Train Epoch: 10 [12800/80000 (16%)]\tLoss: 105238.484375\n",
      "Critic Train Epoch: 10 [19200/80000 (24%)]\tLoss: 93600.195312\n",
      "Critic Train Epoch: 10 [25600/80000 (32%)]\tLoss: 112820.796875\n",
      "Critic Train Epoch: 10 [32000/80000 (40%)]\tLoss: 108895.671875\n",
      "Critic Train Epoch: 10 [38400/80000 (48%)]\tLoss: 93964.679688\n",
      "Critic Train Epoch: 10 [44800/80000 (56%)]\tLoss: 91093.421875\n",
      "Critic Train Epoch: 10 [51200/80000 (64%)]\tLoss: 86587.968750\n",
      "Critic Train Epoch: 10 [57600/80000 (72%)]\tLoss: 101743.085938\n",
      "Critic Train Epoch: 10 [64000/80000 (80%)]\tLoss: 98037.281250\n",
      "Critic Train Epoch: 10 [70400/80000 (88%)]\tLoss: 101761.007812\n",
      "Critic Train Epoch: 10 [76800/80000 (96%)]\tLoss: 86179.554688\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 2.1068\n",
      "Actor Train Epoch: 11 [0/80000 (0%)]\tLoss: 0.060500\n",
      "Actor Train Epoch: 11 [6400/80000 (8%)]\tLoss: 0.059135\n",
      "Actor Train Epoch: 11 [12800/80000 (16%)]\tLoss: 0.059854\n",
      "Actor Train Epoch: 11 [19200/80000 (24%)]\tLoss: 0.061922\n",
      "Actor Train Epoch: 11 [25600/80000 (32%)]\tLoss: 0.060656\n",
      "Actor Train Epoch: 11 [32000/80000 (40%)]\tLoss: 0.060877\n",
      "Actor Train Epoch: 11 [38400/80000 (48%)]\tLoss: 0.058574\n",
      "Actor Train Epoch: 11 [44800/80000 (56%)]\tLoss: 0.061000\n",
      "Actor Train Epoch: 11 [51200/80000 (64%)]\tLoss: 0.060608\n",
      "Actor Train Epoch: 11 [57600/80000 (72%)]\tLoss: 0.061369\n",
      "Actor Train Epoch: 11 [64000/80000 (80%)]\tLoss: 0.058249\n",
      "Actor Train Epoch: 11 [70400/80000 (88%)]\tLoss: 0.059171\n",
      "Actor Train Epoch: 11 [76800/80000 (96%)]\tLoss: 0.057445\n",
      "Critic Train Epoch: 11 [0/80000 (0%)]\tLoss: 89960.312500\n",
      "Critic Train Epoch: 11 [6400/80000 (8%)]\tLoss: 85525.312500\n",
      "Critic Train Epoch: 11 [12800/80000 (16%)]\tLoss: 94673.445312\n",
      "Critic Train Epoch: 11 [19200/80000 (24%)]\tLoss: 81373.414062\n",
      "Critic Train Epoch: 11 [25600/80000 (32%)]\tLoss: 91973.914062\n",
      "Critic Train Epoch: 11 [32000/80000 (40%)]\tLoss: 100452.335938\n",
      "Critic Train Epoch: 11 [38400/80000 (48%)]\tLoss: 92716.203125\n",
      "Critic Train Epoch: 11 [44800/80000 (56%)]\tLoss: 93130.718750\n",
      "Critic Train Epoch: 11 [51200/80000 (64%)]\tLoss: 102054.734375\n",
      "Critic Train Epoch: 11 [57600/80000 (72%)]\tLoss: 86317.179688\n",
      "Critic Train Epoch: 11 [64000/80000 (80%)]\tLoss: 94879.265625\n",
      "Critic Train Epoch: 11 [70400/80000 (88%)]\tLoss: 91506.906250\n",
      "Critic Train Epoch: 11 [76800/80000 (96%)]\tLoss: 97884.101562\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.6316\n",
      "Actor Train Epoch: 12 [0/80000 (0%)]\tLoss: 0.127317\n",
      "Actor Train Epoch: 12 [6400/80000 (8%)]\tLoss: 0.058463\n",
      "Actor Train Epoch: 12 [12800/80000 (16%)]\tLoss: 0.058234\n",
      "Actor Train Epoch: 12 [19200/80000 (24%)]\tLoss: 0.125319\n",
      "Actor Train Epoch: 12 [25600/80000 (32%)]\tLoss: 0.059718\n",
      "Actor Train Epoch: 12 [32000/80000 (40%)]\tLoss: 0.057077\n",
      "Actor Train Epoch: 12 [38400/80000 (48%)]\tLoss: 0.056369\n",
      "Actor Train Epoch: 12 [44800/80000 (56%)]\tLoss: 0.060541\n",
      "Actor Train Epoch: 12 [51200/80000 (64%)]\tLoss: 0.057507\n",
      "Actor Train Epoch: 12 [57600/80000 (72%)]\tLoss: 0.123871\n",
      "Actor Train Epoch: 12 [64000/80000 (80%)]\tLoss: 0.058646\n",
      "Actor Train Epoch: 12 [70400/80000 (88%)]\tLoss: 0.126541\n",
      "Actor Train Epoch: 12 [76800/80000 (96%)]\tLoss: 0.057467\n",
      "Critic Train Epoch: 12 [0/80000 (0%)]\tLoss: 97241.046875\n",
      "Critic Train Epoch: 12 [6400/80000 (8%)]\tLoss: 83227.531250\n",
      "Critic Train Epoch: 12 [12800/80000 (16%)]\tLoss: 95553.867188\n",
      "Critic Train Epoch: 12 [19200/80000 (24%)]\tLoss: 94791.460938\n",
      "Critic Train Epoch: 12 [25600/80000 (32%)]\tLoss: 89073.312500\n",
      "Critic Train Epoch: 12 [32000/80000 (40%)]\tLoss: 95275.140625\n",
      "Critic Train Epoch: 12 [38400/80000 (48%)]\tLoss: 91230.242188\n",
      "Critic Train Epoch: 12 [44800/80000 (56%)]\tLoss: 90919.695312\n",
      "Critic Train Epoch: 12 [51200/80000 (64%)]\tLoss: 102344.718750\n",
      "Critic Train Epoch: 12 [57600/80000 (72%)]\tLoss: 99490.367188\n",
      "Critic Train Epoch: 12 [64000/80000 (80%)]\tLoss: 99071.562500\n",
      "Critic Train Epoch: 12 [70400/80000 (88%)]\tLoss: 89330.750000\n",
      "Critic Train Epoch: 12 [76800/80000 (96%)]\tLoss: 103890.984375\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.6231\n",
      "Actor Train Epoch: 13 [0/80000 (0%)]\tLoss: 0.056374\n",
      "Actor Train Epoch: 13 [6400/80000 (8%)]\tLoss: 0.057091\n",
      "Actor Train Epoch: 13 [12800/80000 (16%)]\tLoss: 0.054683\n",
      "Actor Train Epoch: 13 [19200/80000 (24%)]\tLoss: 0.056409\n",
      "Actor Train Epoch: 13 [25600/80000 (32%)]\tLoss: 0.057435\n",
      "Actor Train Epoch: 13 [32000/80000 (40%)]\tLoss: 0.058649\n",
      "Actor Train Epoch: 13 [38400/80000 (48%)]\tLoss: 0.122952\n",
      "Actor Train Epoch: 13 [44800/80000 (56%)]\tLoss: 0.055608\n",
      "Actor Train Epoch: 13 [51200/80000 (64%)]\tLoss: 0.056565\n",
      "Actor Train Epoch: 13 [57600/80000 (72%)]\tLoss: 0.056529\n",
      "Actor Train Epoch: 13 [64000/80000 (80%)]\tLoss: 0.056443\n",
      "Actor Train Epoch: 13 [70400/80000 (88%)]\tLoss: 0.124198\n",
      "Actor Train Epoch: 13 [76800/80000 (96%)]\tLoss: 0.123684\n",
      "Critic Train Epoch: 13 [0/80000 (0%)]\tLoss: 94248.804688\n",
      "Critic Train Epoch: 13 [6400/80000 (8%)]\tLoss: 109165.968750\n",
      "Critic Train Epoch: 13 [12800/80000 (16%)]\tLoss: 92585.890625\n",
      "Critic Train Epoch: 13 [19200/80000 (24%)]\tLoss: 110294.203125\n",
      "Critic Train Epoch: 13 [25600/80000 (32%)]\tLoss: 92723.125000\n",
      "Critic Train Epoch: 13 [32000/80000 (40%)]\tLoss: 99881.460938\n",
      "Critic Train Epoch: 13 [38400/80000 (48%)]\tLoss: 87623.132812\n",
      "Critic Train Epoch: 13 [44800/80000 (56%)]\tLoss: 95045.953125\n",
      "Critic Train Epoch: 13 [51200/80000 (64%)]\tLoss: 97451.765625\n",
      "Critic Train Epoch: 13 [57600/80000 (72%)]\tLoss: 86911.640625\n",
      "Critic Train Epoch: 13 [64000/80000 (80%)]\tLoss: 106709.273438\n",
      "Critic Train Epoch: 13 [70400/80000 (88%)]\tLoss: 102981.843750\n",
      "Critic Train Epoch: 13 [76800/80000 (96%)]\tLoss: 98560.046875\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 2.0487\n",
      "Actor Train Epoch: 14 [0/80000 (0%)]\tLoss: 0.056987\n",
      "Actor Train Epoch: 14 [6400/80000 (8%)]\tLoss: 0.054930\n",
      "Actor Train Epoch: 14 [12800/80000 (16%)]\tLoss: 0.057197\n",
      "Actor Train Epoch: 14 [19200/80000 (24%)]\tLoss: 0.055048\n",
      "Actor Train Epoch: 14 [25600/80000 (32%)]\tLoss: 0.056116\n",
      "Actor Train Epoch: 14 [32000/80000 (40%)]\tLoss: 0.053236\n",
      "Actor Train Epoch: 14 [38400/80000 (48%)]\tLoss: 0.055635\n",
      "Actor Train Epoch: 14 [44800/80000 (56%)]\tLoss: 0.059485\n",
      "Actor Train Epoch: 14 [51200/80000 (64%)]\tLoss: 0.056335\n",
      "Actor Train Epoch: 14 [57600/80000 (72%)]\tLoss: 0.056470\n",
      "Actor Train Epoch: 14 [64000/80000 (80%)]\tLoss: 0.053955\n",
      "Actor Train Epoch: 14 [70400/80000 (88%)]\tLoss: 0.056063\n",
      "Actor Train Epoch: 14 [76800/80000 (96%)]\tLoss: 0.054601\n",
      "Critic Train Epoch: 14 [0/80000 (0%)]\tLoss: 79377.945312\n",
      "Critic Train Epoch: 14 [6400/80000 (8%)]\tLoss: 80313.078125\n",
      "Critic Train Epoch: 14 [12800/80000 (16%)]\tLoss: 99309.296875\n",
      "Critic Train Epoch: 14 [19200/80000 (24%)]\tLoss: 103007.828125\n",
      "Critic Train Epoch: 14 [25600/80000 (32%)]\tLoss: 90837.640625\n",
      "Critic Train Epoch: 14 [32000/80000 (40%)]\tLoss: 96873.765625\n",
      "Critic Train Epoch: 14 [38400/80000 (48%)]\tLoss: 95783.414062\n",
      "Critic Train Epoch: 14 [44800/80000 (56%)]\tLoss: 93856.726562\n",
      "Critic Train Epoch: 14 [51200/80000 (64%)]\tLoss: 86098.710938\n",
      "Critic Train Epoch: 14 [57600/80000 (72%)]\tLoss: 105212.953125\n",
      "Critic Train Epoch: 14 [64000/80000 (80%)]\tLoss: 86981.164062\n",
      "Critic Train Epoch: 14 [70400/80000 (88%)]\tLoss: 106879.640625\n",
      "Critic Train Epoch: 14 [76800/80000 (96%)]\tLoss: 94001.257812\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.8031\n",
      "Actor Train Epoch: 15 [0/80000 (0%)]\tLoss: 0.056167\n",
      "Actor Train Epoch: 15 [6400/80000 (8%)]\tLoss: 0.122125\n",
      "Actor Train Epoch: 15 [12800/80000 (16%)]\tLoss: 0.056260\n",
      "Actor Train Epoch: 15 [19200/80000 (24%)]\tLoss: 0.124315\n",
      "Actor Train Epoch: 15 [25600/80000 (32%)]\tLoss: 0.054093\n",
      "Actor Train Epoch: 15 [32000/80000 (40%)]\tLoss: 0.125686\n",
      "Actor Train Epoch: 15 [38400/80000 (48%)]\tLoss: 0.054929\n",
      "Actor Train Epoch: 15 [44800/80000 (56%)]\tLoss: 0.056064\n",
      "Actor Train Epoch: 15 [51200/80000 (64%)]\tLoss: 0.124102\n",
      "Actor Train Epoch: 15 [57600/80000 (72%)]\tLoss: 0.189793\n",
      "Actor Train Epoch: 15 [64000/80000 (80%)]\tLoss: 0.055847\n",
      "Actor Train Epoch: 15 [70400/80000 (88%)]\tLoss: 0.122569\n",
      "Actor Train Epoch: 15 [76800/80000 (96%)]\tLoss: 0.190204\n",
      "Critic Train Epoch: 15 [0/80000 (0%)]\tLoss: 84964.664062\n",
      "Critic Train Epoch: 15 [6400/80000 (8%)]\tLoss: 86251.609375\n",
      "Critic Train Epoch: 15 [12800/80000 (16%)]\tLoss: 89967.828125\n",
      "Critic Train Epoch: 15 [19200/80000 (24%)]\tLoss: 93826.929688\n",
      "Critic Train Epoch: 15 [25600/80000 (32%)]\tLoss: 100391.062500\n",
      "Critic Train Epoch: 15 [32000/80000 (40%)]\tLoss: 88911.468750\n",
      "Critic Train Epoch: 15 [38400/80000 (48%)]\tLoss: 89530.156250\n",
      "Critic Train Epoch: 15 [44800/80000 (56%)]\tLoss: 95691.406250\n",
      "Critic Train Epoch: 15 [51200/80000 (64%)]\tLoss: 93148.828125\n",
      "Critic Train Epoch: 15 [57600/80000 (72%)]\tLoss: 88348.046875\n",
      "Critic Train Epoch: 15 [64000/80000 (80%)]\tLoss: 104814.421875\n",
      "Critic Train Epoch: 15 [70400/80000 (88%)]\tLoss: 98650.117188\n",
      "Critic Train Epoch: 15 [76800/80000 (96%)]\tLoss: 106502.273438\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.9064\n",
      "Actor Train Epoch: 16 [0/80000 (0%)]\tLoss: 0.054475\n",
      "Actor Train Epoch: 16 [6400/80000 (8%)]\tLoss: 0.054800\n",
      "Actor Train Epoch: 16 [12800/80000 (16%)]\tLoss: 0.054235\n",
      "Actor Train Epoch: 16 [19200/80000 (24%)]\tLoss: 0.056433\n",
      "Actor Train Epoch: 16 [25600/80000 (32%)]\tLoss: 0.057040\n",
      "Actor Train Epoch: 16 [32000/80000 (40%)]\tLoss: 0.052378\n",
      "Actor Train Epoch: 16 [38400/80000 (48%)]\tLoss: 0.055188\n",
      "Actor Train Epoch: 16 [44800/80000 (56%)]\tLoss: 0.123474\n",
      "Actor Train Epoch: 16 [51200/80000 (64%)]\tLoss: 0.054215\n",
      "Actor Train Epoch: 16 [57600/80000 (72%)]\tLoss: 0.056787\n",
      "Actor Train Epoch: 16 [64000/80000 (80%)]\tLoss: 0.193100\n",
      "Actor Train Epoch: 16 [70400/80000 (88%)]\tLoss: 0.055603\n",
      "Actor Train Epoch: 16 [76800/80000 (96%)]\tLoss: 0.054930\n",
      "Critic Train Epoch: 16 [0/80000 (0%)]\tLoss: 104396.312500\n",
      "Critic Train Epoch: 16 [6400/80000 (8%)]\tLoss: 97316.250000\n",
      "Critic Train Epoch: 16 [12800/80000 (16%)]\tLoss: 97063.187500\n",
      "Critic Train Epoch: 16 [19200/80000 (24%)]\tLoss: 83827.281250\n",
      "Critic Train Epoch: 16 [25600/80000 (32%)]\tLoss: 89873.968750\n",
      "Critic Train Epoch: 16 [32000/80000 (40%)]\tLoss: 78638.671875\n",
      "Critic Train Epoch: 16 [38400/80000 (48%)]\tLoss: 96947.429688\n",
      "Critic Train Epoch: 16 [44800/80000 (56%)]\tLoss: 100146.101562\n",
      "Critic Train Epoch: 16 [51200/80000 (64%)]\tLoss: 91193.125000\n",
      "Critic Train Epoch: 16 [57600/80000 (72%)]\tLoss: 88714.234375\n",
      "Critic Train Epoch: 16 [64000/80000 (80%)]\tLoss: 77412.109375\n",
      "Critic Train Epoch: 16 [70400/80000 (88%)]\tLoss: 92506.078125\n",
      "Critic Train Epoch: 16 [76800/80000 (96%)]\tLoss: 104529.906250\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 2.0405\n",
      "Actor Train Epoch: 17 [0/80000 (0%)]\tLoss: 0.121789\n",
      "Actor Train Epoch: 17 [6400/80000 (8%)]\tLoss: 0.055538\n",
      "Actor Train Epoch: 17 [12800/80000 (16%)]\tLoss: 0.052658\n",
      "Actor Train Epoch: 17 [19200/80000 (24%)]\tLoss: 0.123641\n",
      "Actor Train Epoch: 17 [25600/80000 (32%)]\tLoss: 0.123188\n",
      "Actor Train Epoch: 17 [32000/80000 (40%)]\tLoss: 0.053841\n",
      "Actor Train Epoch: 17 [38400/80000 (48%)]\tLoss: 0.122966\n",
      "Actor Train Epoch: 17 [44800/80000 (56%)]\tLoss: 0.053296\n",
      "Actor Train Epoch: 17 [51200/80000 (64%)]\tLoss: 0.055729\n",
      "Actor Train Epoch: 17 [57600/80000 (72%)]\tLoss: 0.054996\n",
      "Actor Train Epoch: 17 [64000/80000 (80%)]\tLoss: 0.052779\n",
      "Actor Train Epoch: 17 [70400/80000 (88%)]\tLoss: 0.055081\n",
      "Actor Train Epoch: 17 [76800/80000 (96%)]\tLoss: 0.053243\n",
      "Critic Train Epoch: 17 [0/80000 (0%)]\tLoss: 96199.000000\n",
      "Critic Train Epoch: 17 [6400/80000 (8%)]\tLoss: 118666.101562\n",
      "Critic Train Epoch: 17 [12800/80000 (16%)]\tLoss: 101075.085938\n",
      "Critic Train Epoch: 17 [19200/80000 (24%)]\tLoss: 87880.359375\n",
      "Critic Train Epoch: 17 [25600/80000 (32%)]\tLoss: 92314.828125\n",
      "Critic Train Epoch: 17 [32000/80000 (40%)]\tLoss: 93623.039062\n",
      "Critic Train Epoch: 17 [38400/80000 (48%)]\tLoss: 85290.250000\n",
      "Critic Train Epoch: 17 [44800/80000 (56%)]\tLoss: 93385.968750\n",
      "Critic Train Epoch: 17 [51200/80000 (64%)]\tLoss: 107535.468750\n",
      "Critic Train Epoch: 17 [57600/80000 (72%)]\tLoss: 82152.242188\n",
      "Critic Train Epoch: 17 [64000/80000 (80%)]\tLoss: 104918.093750\n",
      "Critic Train Epoch: 17 [70400/80000 (88%)]\tLoss: 96561.984375\n",
      "Critic Train Epoch: 17 [76800/80000 (96%)]\tLoss: 93236.437500\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 2.2808\n",
      "Actor Train Epoch: 18 [0/80000 (0%)]\tLoss: 0.052501\n",
      "Actor Train Epoch: 18 [6400/80000 (8%)]\tLoss: 0.054831\n",
      "Actor Train Epoch: 18 [12800/80000 (16%)]\tLoss: 0.053570\n",
      "Actor Train Epoch: 18 [19200/80000 (24%)]\tLoss: 0.054517\n",
      "Actor Train Epoch: 18 [25600/80000 (32%)]\tLoss: 0.054087\n",
      "Actor Train Epoch: 18 [32000/80000 (40%)]\tLoss: 0.123045\n",
      "Actor Train Epoch: 18 [38400/80000 (48%)]\tLoss: 0.120383\n",
      "Actor Train Epoch: 18 [44800/80000 (56%)]\tLoss: 0.053826\n",
      "Actor Train Epoch: 18 [51200/80000 (64%)]\tLoss: 0.055860\n",
      "Actor Train Epoch: 18 [57600/80000 (72%)]\tLoss: 0.122013\n",
      "Actor Train Epoch: 18 [64000/80000 (80%)]\tLoss: 0.122427\n",
      "Actor Train Epoch: 18 [70400/80000 (88%)]\tLoss: 0.055870\n",
      "Actor Train Epoch: 18 [76800/80000 (96%)]\tLoss: 0.189691\n",
      "Critic Train Epoch: 18 [0/80000 (0%)]\tLoss: 86029.703125\n",
      "Critic Train Epoch: 18 [6400/80000 (8%)]\tLoss: 86230.312500\n",
      "Critic Train Epoch: 18 [12800/80000 (16%)]\tLoss: 106527.773438\n",
      "Critic Train Epoch: 18 [19200/80000 (24%)]\tLoss: 91104.312500\n",
      "Critic Train Epoch: 18 [25600/80000 (32%)]\tLoss: 103545.742188\n",
      "Critic Train Epoch: 18 [32000/80000 (40%)]\tLoss: 101848.023438\n",
      "Critic Train Epoch: 18 [38400/80000 (48%)]\tLoss: 84064.140625\n",
      "Critic Train Epoch: 18 [44800/80000 (56%)]\tLoss: 95626.125000\n",
      "Critic Train Epoch: 18 [51200/80000 (64%)]\tLoss: 90683.031250\n",
      "Critic Train Epoch: 18 [57600/80000 (72%)]\tLoss: 92400.250000\n",
      "Critic Train Epoch: 18 [64000/80000 (80%)]\tLoss: 103197.000000\n",
      "Critic Train Epoch: 18 [70400/80000 (88%)]\tLoss: 103505.609375\n",
      "Critic Train Epoch: 18 [76800/80000 (96%)]\tLoss: 94102.000000\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 2.1688\n",
      "Actor Train Epoch: 19 [0/80000 (0%)]\tLoss: 0.054395\n",
      "Actor Train Epoch: 19 [6400/80000 (8%)]\tLoss: 0.123170\n",
      "Actor Train Epoch: 19 [12800/80000 (16%)]\tLoss: 0.120177\n",
      "Actor Train Epoch: 19 [19200/80000 (24%)]\tLoss: 0.053016\n",
      "Actor Train Epoch: 19 [25600/80000 (32%)]\tLoss: 0.056819\n",
      "Actor Train Epoch: 19 [32000/80000 (40%)]\tLoss: 0.124149\n",
      "Actor Train Epoch: 19 [38400/80000 (48%)]\tLoss: 0.051962\n",
      "Actor Train Epoch: 19 [44800/80000 (56%)]\tLoss: 0.054273\n",
      "Actor Train Epoch: 19 [51200/80000 (64%)]\tLoss: 0.054073\n",
      "Actor Train Epoch: 19 [57600/80000 (72%)]\tLoss: 0.054337\n",
      "Actor Train Epoch: 19 [64000/80000 (80%)]\tLoss: 0.053152\n",
      "Actor Train Epoch: 19 [70400/80000 (88%)]\tLoss: 0.055647\n",
      "Actor Train Epoch: 19 [76800/80000 (96%)]\tLoss: 0.122876\n",
      "Critic Train Epoch: 19 [0/80000 (0%)]\tLoss: 92332.679688\n",
      "Critic Train Epoch: 19 [6400/80000 (8%)]\tLoss: 89684.906250\n",
      "Critic Train Epoch: 19 [12800/80000 (16%)]\tLoss: 96909.578125\n",
      "Critic Train Epoch: 19 [19200/80000 (24%)]\tLoss: 98069.492188\n",
      "Critic Train Epoch: 19 [25600/80000 (32%)]\tLoss: 95893.265625\n",
      "Critic Train Epoch: 19 [32000/80000 (40%)]\tLoss: 105769.093750\n",
      "Critic Train Epoch: 19 [38400/80000 (48%)]\tLoss: 95651.648438\n",
      "Critic Train Epoch: 19 [44800/80000 (56%)]\tLoss: 90192.648438\n",
      "Critic Train Epoch: 19 [51200/80000 (64%)]\tLoss: 103638.140625\n",
      "Critic Train Epoch: 19 [57600/80000 (72%)]\tLoss: 93593.984375\n",
      "Critic Train Epoch: 19 [64000/80000 (80%)]\tLoss: 85298.992188\n",
      "Critic Train Epoch: 19 [70400/80000 (88%)]\tLoss: 90213.132812\n",
      "Critic Train Epoch: 19 [76800/80000 (96%)]\tLoss: 93581.078125\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.9987\n",
      "Actor Train Epoch: 20 [0/80000 (0%)]\tLoss: 0.052811\n",
      "Actor Train Epoch: 20 [6400/80000 (8%)]\tLoss: 0.056634\n",
      "Actor Train Epoch: 20 [12800/80000 (16%)]\tLoss: 0.057324\n",
      "Actor Train Epoch: 20 [19200/80000 (24%)]\tLoss: 0.051690\n",
      "Actor Train Epoch: 20 [25600/80000 (32%)]\tLoss: 0.054602\n",
      "Actor Train Epoch: 20 [32000/80000 (40%)]\tLoss: 0.122624\n",
      "Actor Train Epoch: 20 [38400/80000 (48%)]\tLoss: 0.122012\n",
      "Actor Train Epoch: 20 [44800/80000 (56%)]\tLoss: 0.052993\n",
      "Actor Train Epoch: 20 [51200/80000 (64%)]\tLoss: 0.053841\n",
      "Actor Train Epoch: 20 [57600/80000 (72%)]\tLoss: 0.053368\n",
      "Actor Train Epoch: 20 [64000/80000 (80%)]\tLoss: 0.053569\n",
      "Actor Train Epoch: 20 [70400/80000 (88%)]\tLoss: 0.189147\n",
      "Actor Train Epoch: 20 [76800/80000 (96%)]\tLoss: 0.054204\n",
      "Critic Train Epoch: 20 [0/80000 (0%)]\tLoss: 98247.156250\n",
      "Critic Train Epoch: 20 [6400/80000 (8%)]\tLoss: 98357.515625\n",
      "Critic Train Epoch: 20 [12800/80000 (16%)]\tLoss: 101149.156250\n",
      "Critic Train Epoch: 20 [19200/80000 (24%)]\tLoss: 101300.257812\n",
      "Critic Train Epoch: 20 [25600/80000 (32%)]\tLoss: 94732.671875\n",
      "Critic Train Epoch: 20 [32000/80000 (40%)]\tLoss: 100253.546875\n",
      "Critic Train Epoch: 20 [38400/80000 (48%)]\tLoss: 96973.171875\n",
      "Critic Train Epoch: 20 [44800/80000 (56%)]\tLoss: 102032.843750\n",
      "Critic Train Epoch: 20 [51200/80000 (64%)]\tLoss: 88907.062500\n",
      "Critic Train Epoch: 20 [57600/80000 (72%)]\tLoss: 90284.484375\n",
      "Critic Train Epoch: 20 [64000/80000 (80%)]\tLoss: 85822.375000\n",
      "Critic Train Epoch: 20 [70400/80000 (88%)]\tLoss: 96819.953125\n",
      "Critic Train Epoch: 20 [76800/80000 (96%)]\tLoss: 101923.343750\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.9772\n",
      "Actor Train Epoch: 21 [0/80000 (0%)]\tLoss: 0.053431\n",
      "Actor Train Epoch: 21 [6400/80000 (8%)]\tLoss: 0.054367\n",
      "Actor Train Epoch: 21 [12800/80000 (16%)]\tLoss: 0.053537\n",
      "Actor Train Epoch: 21 [19200/80000 (24%)]\tLoss: 0.054474\n",
      "Actor Train Epoch: 21 [25600/80000 (32%)]\tLoss: 0.055304\n",
      "Actor Train Epoch: 21 [32000/80000 (40%)]\tLoss: 0.054850\n",
      "Actor Train Epoch: 21 [38400/80000 (48%)]\tLoss: 0.053852\n",
      "Actor Train Epoch: 21 [44800/80000 (56%)]\tLoss: 0.055429\n",
      "Actor Train Epoch: 21 [51200/80000 (64%)]\tLoss: 0.123636\n",
      "Actor Train Epoch: 21 [57600/80000 (72%)]\tLoss: 0.057723\n",
      "Actor Train Epoch: 21 [64000/80000 (80%)]\tLoss: 0.053567\n",
      "Actor Train Epoch: 21 [70400/80000 (88%)]\tLoss: 0.260519\n",
      "Actor Train Epoch: 21 [76800/80000 (96%)]\tLoss: 0.054068\n",
      "Critic Train Epoch: 21 [0/80000 (0%)]\tLoss: 92866.023438\n",
      "Critic Train Epoch: 21 [6400/80000 (8%)]\tLoss: 96194.085938\n",
      "Critic Train Epoch: 21 [12800/80000 (16%)]\tLoss: 95500.578125\n",
      "Critic Train Epoch: 21 [19200/80000 (24%)]\tLoss: 96576.625000\n",
      "Critic Train Epoch: 21 [25600/80000 (32%)]\tLoss: 86266.953125\n",
      "Critic Train Epoch: 21 [32000/80000 (40%)]\tLoss: 101746.523438\n",
      "Critic Train Epoch: 21 [38400/80000 (48%)]\tLoss: 94542.500000\n",
      "Critic Train Epoch: 21 [44800/80000 (56%)]\tLoss: 87050.468750\n",
      "Critic Train Epoch: 21 [51200/80000 (64%)]\tLoss: 81385.320312\n",
      "Critic Train Epoch: 21 [57600/80000 (72%)]\tLoss: 108052.546875\n",
      "Critic Train Epoch: 21 [64000/80000 (80%)]\tLoss: 100432.726562\n",
      "Critic Train Epoch: 21 [70400/80000 (88%)]\tLoss: 84865.671875\n",
      "Critic Train Epoch: 21 [76800/80000 (96%)]\tLoss: 95312.906250\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 2.0394\n",
      "Actor Train Epoch: 22 [0/80000 (0%)]\tLoss: 0.123984\n",
      "Actor Train Epoch: 22 [6400/80000 (8%)]\tLoss: 0.052533\n",
      "Actor Train Epoch: 22 [12800/80000 (16%)]\tLoss: 0.054443\n",
      "Actor Train Epoch: 22 [19200/80000 (24%)]\tLoss: 0.052971\n",
      "Actor Train Epoch: 22 [25600/80000 (32%)]\tLoss: 0.054303\n",
      "Actor Train Epoch: 22 [32000/80000 (40%)]\tLoss: 0.056868\n",
      "Actor Train Epoch: 22 [38400/80000 (48%)]\tLoss: 0.053791\n",
      "Actor Train Epoch: 22 [44800/80000 (56%)]\tLoss: 0.054313\n",
      "Actor Train Epoch: 22 [51200/80000 (64%)]\tLoss: 0.052933\n",
      "Actor Train Epoch: 22 [57600/80000 (72%)]\tLoss: 0.053589\n",
      "Actor Train Epoch: 22 [64000/80000 (80%)]\tLoss: 0.053191\n",
      "Actor Train Epoch: 22 [70400/80000 (88%)]\tLoss: 0.053982\n",
      "Actor Train Epoch: 22 [76800/80000 (96%)]\tLoss: 0.053169\n",
      "Critic Train Epoch: 22 [0/80000 (0%)]\tLoss: 78330.468750\n",
      "Critic Train Epoch: 22 [6400/80000 (8%)]\tLoss: 94824.265625\n",
      "Critic Train Epoch: 22 [12800/80000 (16%)]\tLoss: 85809.515625\n",
      "Critic Train Epoch: 22 [19200/80000 (24%)]\tLoss: 87882.250000\n",
      "Critic Train Epoch: 22 [25600/80000 (32%)]\tLoss: 98146.843750\n",
      "Critic Train Epoch: 22 [32000/80000 (40%)]\tLoss: 92196.109375\n",
      "Critic Train Epoch: 22 [38400/80000 (48%)]\tLoss: 79066.968750\n",
      "Critic Train Epoch: 22 [44800/80000 (56%)]\tLoss: 97934.156250\n",
      "Critic Train Epoch: 22 [51200/80000 (64%)]\tLoss: 106116.859375\n",
      "Critic Train Epoch: 22 [57600/80000 (72%)]\tLoss: 90526.500000\n",
      "Critic Train Epoch: 22 [64000/80000 (80%)]\tLoss: 89833.460938\n",
      "Critic Train Epoch: 22 [70400/80000 (88%)]\tLoss: 92111.000000\n",
      "Critic Train Epoch: 22 [76800/80000 (96%)]\tLoss: 104406.750000\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 2.1543\n",
      "Actor Train Epoch: 23 [0/80000 (0%)]\tLoss: 0.121139\n",
      "Actor Train Epoch: 23 [6400/80000 (8%)]\tLoss: 0.053895\n",
      "Actor Train Epoch: 23 [12800/80000 (16%)]\tLoss: 0.055760\n",
      "Actor Train Epoch: 23 [19200/80000 (24%)]\tLoss: 0.124178\n",
      "Actor Train Epoch: 23 [25600/80000 (32%)]\tLoss: 0.122270\n",
      "Actor Train Epoch: 23 [32000/80000 (40%)]\tLoss: 0.053920\n",
      "Actor Train Epoch: 23 [38400/80000 (48%)]\tLoss: 0.054164\n",
      "Actor Train Epoch: 23 [44800/80000 (56%)]\tLoss: 0.053422\n",
      "Actor Train Epoch: 23 [51200/80000 (64%)]\tLoss: 0.055685\n",
      "Actor Train Epoch: 23 [57600/80000 (72%)]\tLoss: 0.121123\n",
      "Actor Train Epoch: 23 [64000/80000 (80%)]\tLoss: 0.052414\n",
      "Actor Train Epoch: 23 [70400/80000 (88%)]\tLoss: 0.119880\n",
      "Actor Train Epoch: 23 [76800/80000 (96%)]\tLoss: 0.055931\n",
      "Critic Train Epoch: 23 [0/80000 (0%)]\tLoss: 98525.843750\n",
      "Critic Train Epoch: 23 [6400/80000 (8%)]\tLoss: 90355.320312\n",
      "Critic Train Epoch: 23 [12800/80000 (16%)]\tLoss: 96847.664062\n",
      "Critic Train Epoch: 23 [19200/80000 (24%)]\tLoss: 100819.351562\n",
      "Critic Train Epoch: 23 [25600/80000 (32%)]\tLoss: 89415.859375\n",
      "Critic Train Epoch: 23 [32000/80000 (40%)]\tLoss: 103991.851562\n",
      "Critic Train Epoch: 23 [38400/80000 (48%)]\tLoss: 111479.218750\n",
      "Critic Train Epoch: 23 [44800/80000 (56%)]\tLoss: 107912.703125\n",
      "Critic Train Epoch: 23 [51200/80000 (64%)]\tLoss: 91727.851562\n",
      "Critic Train Epoch: 23 [57600/80000 (72%)]\tLoss: 88503.710938\n",
      "Critic Train Epoch: 23 [64000/80000 (80%)]\tLoss: 87094.078125\n",
      "Critic Train Epoch: 23 [70400/80000 (88%)]\tLoss: 97871.179688\n",
      "Critic Train Epoch: 23 [76800/80000 (96%)]\tLoss: 100092.937500\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.9110\n",
      "Actor Train Epoch: 24 [0/80000 (0%)]\tLoss: 0.056802\n",
      "Actor Train Epoch: 24 [6400/80000 (8%)]\tLoss: 0.056268\n",
      "Actor Train Epoch: 24 [12800/80000 (16%)]\tLoss: 0.054951\n",
      "Actor Train Epoch: 24 [19200/80000 (24%)]\tLoss: 0.054053\n",
      "Actor Train Epoch: 24 [25600/80000 (32%)]\tLoss: 0.055536\n",
      "Actor Train Epoch: 24 [32000/80000 (40%)]\tLoss: 0.054585\n",
      "Actor Train Epoch: 24 [38400/80000 (48%)]\tLoss: 0.124142\n",
      "Actor Train Epoch: 24 [44800/80000 (56%)]\tLoss: 0.056243\n",
      "Actor Train Epoch: 24 [51200/80000 (64%)]\tLoss: 0.053872\n",
      "Actor Train Epoch: 24 [57600/80000 (72%)]\tLoss: 0.055322\n",
      "Actor Train Epoch: 24 [64000/80000 (80%)]\tLoss: 0.121268\n",
      "Actor Train Epoch: 24 [70400/80000 (88%)]\tLoss: 0.056364\n",
      "Actor Train Epoch: 24 [76800/80000 (96%)]\tLoss: 0.056682\n",
      "Critic Train Epoch: 24 [0/80000 (0%)]\tLoss: 101637.695312\n",
      "Critic Train Epoch: 24 [6400/80000 (8%)]\tLoss: 100243.375000\n",
      "Critic Train Epoch: 24 [12800/80000 (16%)]\tLoss: 97018.171875\n",
      "Critic Train Epoch: 24 [19200/80000 (24%)]\tLoss: 107498.148438\n",
      "Critic Train Epoch: 24 [25600/80000 (32%)]\tLoss: 99831.695312\n",
      "Critic Train Epoch: 24 [32000/80000 (40%)]\tLoss: 101724.109375\n",
      "Critic Train Epoch: 24 [38400/80000 (48%)]\tLoss: 85832.601562\n",
      "Critic Train Epoch: 24 [44800/80000 (56%)]\tLoss: 81624.867188\n",
      "Critic Train Epoch: 24 [51200/80000 (64%)]\tLoss: 81394.429688\n",
      "Critic Train Epoch: 24 [57600/80000 (72%)]\tLoss: 97551.039062\n",
      "Critic Train Epoch: 24 [64000/80000 (80%)]\tLoss: 82290.609375\n",
      "Critic Train Epoch: 24 [70400/80000 (88%)]\tLoss: 101334.093750\n",
      "Critic Train Epoch: 24 [76800/80000 (96%)]\tLoss: 98855.421875\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.8865\n",
      "Actor Train Epoch: 25 [0/80000 (0%)]\tLoss: 0.122060\n",
      "Actor Train Epoch: 25 [6400/80000 (8%)]\tLoss: 0.052642\n",
      "Actor Train Epoch: 25 [12800/80000 (16%)]\tLoss: 0.054630\n",
      "Actor Train Epoch: 25 [19200/80000 (24%)]\tLoss: 0.052973\n",
      "Actor Train Epoch: 25 [25600/80000 (32%)]\tLoss: 0.123602\n",
      "Actor Train Epoch: 25 [32000/80000 (40%)]\tLoss: 0.122896\n",
      "Actor Train Epoch: 25 [38400/80000 (48%)]\tLoss: 0.055686\n",
      "Actor Train Epoch: 25 [44800/80000 (56%)]\tLoss: 0.055529\n",
      "Actor Train Epoch: 25 [51200/80000 (64%)]\tLoss: 0.055036\n",
      "Actor Train Epoch: 25 [57600/80000 (72%)]\tLoss: 0.055459\n",
      "Actor Train Epoch: 25 [64000/80000 (80%)]\tLoss: 0.053539\n",
      "Actor Train Epoch: 25 [70400/80000 (88%)]\tLoss: 0.121270\n",
      "Actor Train Epoch: 25 [76800/80000 (96%)]\tLoss: 0.125195\n",
      "Critic Train Epoch: 25 [0/80000 (0%)]\tLoss: 94340.515625\n",
      "Critic Train Epoch: 25 [6400/80000 (8%)]\tLoss: 83443.226562\n",
      "Critic Train Epoch: 25 [12800/80000 (16%)]\tLoss: 89818.945312\n",
      "Critic Train Epoch: 25 [19200/80000 (24%)]\tLoss: 92796.328125\n",
      "Critic Train Epoch: 25 [25600/80000 (32%)]\tLoss: 91846.507812\n",
      "Critic Train Epoch: 25 [32000/80000 (40%)]\tLoss: 96804.335938\n",
      "Critic Train Epoch: 25 [38400/80000 (48%)]\tLoss: 88810.718750\n",
      "Critic Train Epoch: 25 [44800/80000 (56%)]\tLoss: 104397.390625\n",
      "Critic Train Epoch: 25 [51200/80000 (64%)]\tLoss: 101903.296875\n",
      "Critic Train Epoch: 25 [57600/80000 (72%)]\tLoss: 100274.046875\n",
      "Critic Train Epoch: 25 [64000/80000 (80%)]\tLoss: 99168.492188\n",
      "Critic Train Epoch: 25 [70400/80000 (88%)]\tLoss: 121601.015625\n",
      "Critic Train Epoch: 25 [76800/80000 (96%)]\tLoss: 81754.921875\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.8041\n",
      "Actor Train Epoch: 26 [0/80000 (0%)]\tLoss: 0.055794\n",
      "Actor Train Epoch: 26 [6400/80000 (8%)]\tLoss: 0.054183\n",
      "Actor Train Epoch: 26 [12800/80000 (16%)]\tLoss: 0.121897\n",
      "Actor Train Epoch: 26 [19200/80000 (24%)]\tLoss: 0.052919\n",
      "Actor Train Epoch: 26 [25600/80000 (32%)]\tLoss: 0.058207\n",
      "Actor Train Epoch: 26 [32000/80000 (40%)]\tLoss: 0.056671\n",
      "Actor Train Epoch: 26 [38400/80000 (48%)]\tLoss: 0.190368\n",
      "Actor Train Epoch: 26 [44800/80000 (56%)]\tLoss: 0.055099\n",
      "Actor Train Epoch: 26 [51200/80000 (64%)]\tLoss: 0.122185\n",
      "Actor Train Epoch: 26 [57600/80000 (72%)]\tLoss: 0.190985\n",
      "Actor Train Epoch: 26 [64000/80000 (80%)]\tLoss: 0.121018\n",
      "Actor Train Epoch: 26 [70400/80000 (88%)]\tLoss: 0.123422\n",
      "Actor Train Epoch: 26 [76800/80000 (96%)]\tLoss: 0.054072\n",
      "Critic Train Epoch: 26 [0/80000 (0%)]\tLoss: 98987.718750\n",
      "Critic Train Epoch: 26 [6400/80000 (8%)]\tLoss: 98053.156250\n",
      "Critic Train Epoch: 26 [12800/80000 (16%)]\tLoss: 98910.046875\n",
      "Critic Train Epoch: 26 [19200/80000 (24%)]\tLoss: 90577.156250\n",
      "Critic Train Epoch: 26 [25600/80000 (32%)]\tLoss: 89524.156250\n",
      "Critic Train Epoch: 26 [32000/80000 (40%)]\tLoss: 97654.828125\n",
      "Critic Train Epoch: 26 [38400/80000 (48%)]\tLoss: 92349.718750\n",
      "Critic Train Epoch: 26 [44800/80000 (56%)]\tLoss: 93410.062500\n",
      "Critic Train Epoch: 26 [51200/80000 (64%)]\tLoss: 90258.734375\n",
      "Critic Train Epoch: 26 [57600/80000 (72%)]\tLoss: 104659.109375\n",
      "Critic Train Epoch: 26 [64000/80000 (80%)]\tLoss: 97252.539062\n",
      "Critic Train Epoch: 26 [70400/80000 (88%)]\tLoss: 89580.382812\n",
      "Critic Train Epoch: 26 [76800/80000 (96%)]\tLoss: 93043.875000\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 2.2581\n",
      "Actor Train Epoch: 27 [0/80000 (0%)]\tLoss: 0.053879\n",
      "Actor Train Epoch: 27 [6400/80000 (8%)]\tLoss: 0.054602\n",
      "Actor Train Epoch: 27 [12800/80000 (16%)]\tLoss: 0.052817\n",
      "Actor Train Epoch: 27 [19200/80000 (24%)]\tLoss: 0.053173\n",
      "Actor Train Epoch: 27 [25600/80000 (32%)]\tLoss: 0.052914\n",
      "Actor Train Epoch: 27 [32000/80000 (40%)]\tLoss: 0.053586\n",
      "Actor Train Epoch: 27 [38400/80000 (48%)]\tLoss: 0.053584\n",
      "Actor Train Epoch: 27 [44800/80000 (56%)]\tLoss: 0.054114\n",
      "Actor Train Epoch: 27 [51200/80000 (64%)]\tLoss: 0.053663\n",
      "Actor Train Epoch: 27 [57600/80000 (72%)]\tLoss: 0.052570\n",
      "Actor Train Epoch: 27 [64000/80000 (80%)]\tLoss: 0.052526\n",
      "Actor Train Epoch: 27 [70400/80000 (88%)]\tLoss: 0.052751\n",
      "Actor Train Epoch: 27 [76800/80000 (96%)]\tLoss: 0.122978\n",
      "Critic Train Epoch: 27 [0/80000 (0%)]\tLoss: 111761.312500\n",
      "Critic Train Epoch: 27 [6400/80000 (8%)]\tLoss: 79995.531250\n",
      "Critic Train Epoch: 27 [12800/80000 (16%)]\tLoss: 86260.164062\n",
      "Critic Train Epoch: 27 [19200/80000 (24%)]\tLoss: 108552.578125\n",
      "Critic Train Epoch: 27 [25600/80000 (32%)]\tLoss: 96045.695312\n",
      "Critic Train Epoch: 27 [32000/80000 (40%)]\tLoss: 89711.031250\n",
      "Critic Train Epoch: 27 [38400/80000 (48%)]\tLoss: 97813.625000\n",
      "Critic Train Epoch: 27 [44800/80000 (56%)]\tLoss: 95470.000000\n",
      "Critic Train Epoch: 27 [51200/80000 (64%)]\tLoss: 98653.656250\n",
      "Critic Train Epoch: 27 [57600/80000 (72%)]\tLoss: 83034.265625\n",
      "Critic Train Epoch: 27 [64000/80000 (80%)]\tLoss: 102321.687500\n",
      "Critic Train Epoch: 27 [70400/80000 (88%)]\tLoss: 88643.687500\n",
      "Critic Train Epoch: 27 [76800/80000 (96%)]\tLoss: 88491.070312\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 2.2225\n",
      "Actor Train Epoch: 28 [0/80000 (0%)]\tLoss: 0.054848\n",
      "Actor Train Epoch: 28 [6400/80000 (8%)]\tLoss: 0.054931\n",
      "Actor Train Epoch: 28 [12800/80000 (16%)]\tLoss: 0.054996\n",
      "Actor Train Epoch: 28 [19200/80000 (24%)]\tLoss: 0.054920\n",
      "Actor Train Epoch: 28 [25600/80000 (32%)]\tLoss: 0.054018\n",
      "Actor Train Epoch: 28 [32000/80000 (40%)]\tLoss: 0.054405\n",
      "Actor Train Epoch: 28 [38400/80000 (48%)]\tLoss: 0.122077\n",
      "Actor Train Epoch: 28 [44800/80000 (56%)]\tLoss: 0.122300\n",
      "Actor Train Epoch: 28 [51200/80000 (64%)]\tLoss: 0.055423\n",
      "Actor Train Epoch: 28 [57600/80000 (72%)]\tLoss: 0.053537\n",
      "Actor Train Epoch: 28 [64000/80000 (80%)]\tLoss: 0.056052\n",
      "Actor Train Epoch: 28 [70400/80000 (88%)]\tLoss: 0.053803\n",
      "Actor Train Epoch: 28 [76800/80000 (96%)]\tLoss: 0.056504\n",
      "Critic Train Epoch: 28 [0/80000 (0%)]\tLoss: 103195.140625\n",
      "Critic Train Epoch: 28 [6400/80000 (8%)]\tLoss: 101003.195312\n",
      "Critic Train Epoch: 28 [12800/80000 (16%)]\tLoss: 99344.093750\n",
      "Critic Train Epoch: 28 [19200/80000 (24%)]\tLoss: 95216.484375\n",
      "Critic Train Epoch: 28 [25600/80000 (32%)]\tLoss: 90707.085938\n",
      "Critic Train Epoch: 28 [32000/80000 (40%)]\tLoss: 87539.210938\n",
      "Critic Train Epoch: 28 [38400/80000 (48%)]\tLoss: 98032.625000\n",
      "Critic Train Epoch: 28 [44800/80000 (56%)]\tLoss: 95885.921875\n",
      "Critic Train Epoch: 28 [51200/80000 (64%)]\tLoss: 90797.343750\n",
      "Critic Train Epoch: 28 [57600/80000 (72%)]\tLoss: 88831.562500\n",
      "Critic Train Epoch: 28 [64000/80000 (80%)]\tLoss: 93634.289062\n",
      "Critic Train Epoch: 28 [70400/80000 (88%)]\tLoss: 88974.664062\n",
      "Critic Train Epoch: 28 [76800/80000 (96%)]\tLoss: 85346.203125\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 2.1033\n",
      "Actor Train Epoch: 29 [0/80000 (0%)]\tLoss: 0.121671\n",
      "Actor Train Epoch: 29 [6400/80000 (8%)]\tLoss: 0.053716\n",
      "Actor Train Epoch: 29 [12800/80000 (16%)]\tLoss: 0.120774\n",
      "Actor Train Epoch: 29 [19200/80000 (24%)]\tLoss: 0.053739\n",
      "Actor Train Epoch: 29 [25600/80000 (32%)]\tLoss: 0.123969\n",
      "Actor Train Epoch: 29 [32000/80000 (40%)]\tLoss: 0.056436\n",
      "Actor Train Epoch: 29 [38400/80000 (48%)]\tLoss: 0.054396\n",
      "Actor Train Epoch: 29 [44800/80000 (56%)]\tLoss: 0.055302\n",
      "Actor Train Epoch: 29 [51200/80000 (64%)]\tLoss: 0.053881\n",
      "Actor Train Epoch: 29 [57600/80000 (72%)]\tLoss: 0.052690\n",
      "Actor Train Epoch: 29 [64000/80000 (80%)]\tLoss: 0.054396\n",
      "Actor Train Epoch: 29 [70400/80000 (88%)]\tLoss: 0.053173\n",
      "Actor Train Epoch: 29 [76800/80000 (96%)]\tLoss: 0.053223\n",
      "Critic Train Epoch: 29 [0/80000 (0%)]\tLoss: 87826.250000\n",
      "Critic Train Epoch: 29 [6400/80000 (8%)]\tLoss: 89850.570312\n",
      "Critic Train Epoch: 29 [12800/80000 (16%)]\tLoss: 96966.125000\n",
      "Critic Train Epoch: 29 [19200/80000 (24%)]\tLoss: 101557.742188\n",
      "Critic Train Epoch: 29 [25600/80000 (32%)]\tLoss: 86370.679688\n",
      "Critic Train Epoch: 29 [32000/80000 (40%)]\tLoss: 91354.546875\n",
      "Critic Train Epoch: 29 [38400/80000 (48%)]\tLoss: 109827.101562\n",
      "Critic Train Epoch: 29 [44800/80000 (56%)]\tLoss: 95255.546875\n",
      "Critic Train Epoch: 29 [51200/80000 (64%)]\tLoss: 103862.484375\n",
      "Critic Train Epoch: 29 [57600/80000 (72%)]\tLoss: 83589.859375\n",
      "Critic Train Epoch: 29 [64000/80000 (80%)]\tLoss: 92313.453125\n",
      "Critic Train Epoch: 29 [70400/80000 (88%)]\tLoss: 86942.070312\n",
      "Critic Train Epoch: 29 [76800/80000 (96%)]\tLoss: 100660.148438\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.8343\n",
      "Actor Train Epoch: 30 [0/80000 (0%)]\tLoss: 0.053180\n",
      "Actor Train Epoch: 30 [6400/80000 (8%)]\tLoss: 0.123383\n",
      "Actor Train Epoch: 30 [12800/80000 (16%)]\tLoss: 0.122838\n",
      "Actor Train Epoch: 30 [19200/80000 (24%)]\tLoss: 0.054632\n",
      "Actor Train Epoch: 30 [25600/80000 (32%)]\tLoss: 0.054481\n",
      "Actor Train Epoch: 30 [32000/80000 (40%)]\tLoss: 0.053742\n",
      "Actor Train Epoch: 30 [38400/80000 (48%)]\tLoss: 0.052538\n",
      "Actor Train Epoch: 30 [44800/80000 (56%)]\tLoss: 0.053269\n",
      "Actor Train Epoch: 30 [51200/80000 (64%)]\tLoss: 0.052613\n",
      "Actor Train Epoch: 30 [57600/80000 (72%)]\tLoss: 0.121474\n",
      "Actor Train Epoch: 30 [64000/80000 (80%)]\tLoss: 0.192184\n",
      "Actor Train Epoch: 30 [70400/80000 (88%)]\tLoss: 0.056829\n",
      "Actor Train Epoch: 30 [76800/80000 (96%)]\tLoss: 0.055463\n",
      "Critic Train Epoch: 30 [0/80000 (0%)]\tLoss: 89154.664062\n",
      "Critic Train Epoch: 30 [6400/80000 (8%)]\tLoss: 94595.562500\n",
      "Critic Train Epoch: 30 [12800/80000 (16%)]\tLoss: 94281.562500\n",
      "Critic Train Epoch: 30 [19200/80000 (24%)]\tLoss: 109839.031250\n",
      "Critic Train Epoch: 30 [25600/80000 (32%)]\tLoss: 91452.718750\n",
      "Critic Train Epoch: 30 [32000/80000 (40%)]\tLoss: 101238.500000\n",
      "Critic Train Epoch: 30 [38400/80000 (48%)]\tLoss: 99357.093750\n",
      "Critic Train Epoch: 30 [44800/80000 (56%)]\tLoss: 94658.335938\n",
      "Critic Train Epoch: 30 [51200/80000 (64%)]\tLoss: 86775.187500\n",
      "Critic Train Epoch: 30 [57600/80000 (72%)]\tLoss: 94005.578125\n",
      "Critic Train Epoch: 30 [64000/80000 (80%)]\tLoss: 93785.250000\n",
      "Critic Train Epoch: 30 [70400/80000 (88%)]\tLoss: 98603.171875\n",
      "Critic Train Epoch: 30 [76800/80000 (96%)]\tLoss: 85062.953125\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 2.1054\n",
      "Actor Train Epoch: 31 [0/80000 (0%)]\tLoss: 0.121051\n",
      "Actor Train Epoch: 31 [6400/80000 (8%)]\tLoss: 0.054807\n",
      "Actor Train Epoch: 31 [12800/80000 (16%)]\tLoss: 0.054149\n",
      "Actor Train Epoch: 31 [19200/80000 (24%)]\tLoss: 0.053593\n",
      "Actor Train Epoch: 31 [25600/80000 (32%)]\tLoss: 0.124137\n",
      "Actor Train Epoch: 31 [32000/80000 (40%)]\tLoss: 0.121402\n",
      "Actor Train Epoch: 31 [38400/80000 (48%)]\tLoss: 0.055573\n",
      "Actor Train Epoch: 31 [44800/80000 (56%)]\tLoss: 0.054855\n",
      "Actor Train Epoch: 31 [51200/80000 (64%)]\tLoss: 0.191044\n",
      "Actor Train Epoch: 31 [57600/80000 (72%)]\tLoss: 0.055599\n",
      "Actor Train Epoch: 31 [64000/80000 (80%)]\tLoss: 0.121083\n",
      "Actor Train Epoch: 31 [70400/80000 (88%)]\tLoss: 0.052785\n",
      "Actor Train Epoch: 31 [76800/80000 (96%)]\tLoss: 0.054878\n",
      "Critic Train Epoch: 31 [0/80000 (0%)]\tLoss: 94981.640625\n",
      "Critic Train Epoch: 31 [6400/80000 (8%)]\tLoss: 105523.406250\n",
      "Critic Train Epoch: 31 [12800/80000 (16%)]\tLoss: 108585.562500\n",
      "Critic Train Epoch: 31 [19200/80000 (24%)]\tLoss: 86618.304688\n",
      "Critic Train Epoch: 31 [25600/80000 (32%)]\tLoss: 82423.554688\n",
      "Critic Train Epoch: 31 [32000/80000 (40%)]\tLoss: 95838.226562\n",
      "Critic Train Epoch: 31 [38400/80000 (48%)]\tLoss: 102755.828125\n",
      "Critic Train Epoch: 31 [44800/80000 (56%)]\tLoss: 88140.828125\n",
      "Critic Train Epoch: 31 [51200/80000 (64%)]\tLoss: 97333.554688\n",
      "Critic Train Epoch: 31 [57600/80000 (72%)]\tLoss: 93907.140625\n",
      "Critic Train Epoch: 31 [64000/80000 (80%)]\tLoss: 85097.796875\n",
      "Critic Train Epoch: 31 [70400/80000 (88%)]\tLoss: 88680.023438\n",
      "Critic Train Epoch: 31 [76800/80000 (96%)]\tLoss: 110185.921875\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.5970\n",
      "Actor Train Epoch: 32 [0/80000 (0%)]\tLoss: 0.053503\n",
      "Actor Train Epoch: 32 [6400/80000 (8%)]\tLoss: 0.053687\n",
      "Actor Train Epoch: 32 [12800/80000 (16%)]\tLoss: 0.122188\n",
      "Actor Train Epoch: 32 [19200/80000 (24%)]\tLoss: 0.052604\n",
      "Actor Train Epoch: 32 [25600/80000 (32%)]\tLoss: 0.052808\n",
      "Actor Train Epoch: 32 [32000/80000 (40%)]\tLoss: 0.053631\n",
      "Actor Train Epoch: 32 [38400/80000 (48%)]\tLoss: 0.191120\n",
      "Actor Train Epoch: 32 [44800/80000 (56%)]\tLoss: 0.053242\n",
      "Actor Train Epoch: 32 [51200/80000 (64%)]\tLoss: 0.055628\n",
      "Actor Train Epoch: 32 [57600/80000 (72%)]\tLoss: 0.053761\n",
      "Actor Train Epoch: 32 [64000/80000 (80%)]\tLoss: 0.122762\n",
      "Actor Train Epoch: 32 [70400/80000 (88%)]\tLoss: 0.122476\n",
      "Actor Train Epoch: 32 [76800/80000 (96%)]\tLoss: 0.053113\n",
      "Critic Train Epoch: 32 [0/80000 (0%)]\tLoss: 100089.875000\n",
      "Critic Train Epoch: 32 [6400/80000 (8%)]\tLoss: 88332.484375\n",
      "Critic Train Epoch: 32 [12800/80000 (16%)]\tLoss: 79841.890625\n",
      "Critic Train Epoch: 32 [19200/80000 (24%)]\tLoss: 89980.726562\n",
      "Critic Train Epoch: 32 [25600/80000 (32%)]\tLoss: 99207.468750\n",
      "Critic Train Epoch: 32 [32000/80000 (40%)]\tLoss: 106894.031250\n",
      "Critic Train Epoch: 32 [38400/80000 (48%)]\tLoss: 91725.703125\n",
      "Critic Train Epoch: 32 [44800/80000 (56%)]\tLoss: 103412.718750\n",
      "Critic Train Epoch: 32 [51200/80000 (64%)]\tLoss: 88617.789062\n",
      "Critic Train Epoch: 32 [57600/80000 (72%)]\tLoss: 92844.734375\n",
      "Critic Train Epoch: 32 [64000/80000 (80%)]\tLoss: 87627.531250\n",
      "Critic Train Epoch: 32 [70400/80000 (88%)]\tLoss: 93373.992188\n",
      "Critic Train Epoch: 32 [76800/80000 (96%)]\tLoss: 104368.031250\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 2.1477\n",
      "Actor Train Epoch: 33 [0/80000 (0%)]\tLoss: 0.053716\n",
      "Actor Train Epoch: 33 [6400/80000 (8%)]\tLoss: 0.053776\n",
      "Actor Train Epoch: 33 [12800/80000 (16%)]\tLoss: 0.054841\n",
      "Actor Train Epoch: 33 [19200/80000 (24%)]\tLoss: 0.054056\n",
      "Actor Train Epoch: 33 [25600/80000 (32%)]\tLoss: 0.054109\n",
      "Actor Train Epoch: 33 [32000/80000 (40%)]\tLoss: 0.123588\n",
      "Actor Train Epoch: 33 [38400/80000 (48%)]\tLoss: 0.054915\n",
      "Actor Train Epoch: 33 [44800/80000 (56%)]\tLoss: 0.052440\n",
      "Actor Train Epoch: 33 [51200/80000 (64%)]\tLoss: 0.056250\n",
      "Actor Train Epoch: 33 [57600/80000 (72%)]\tLoss: 0.052271\n",
      "Actor Train Epoch: 33 [64000/80000 (80%)]\tLoss: 0.122262\n",
      "Actor Train Epoch: 33 [70400/80000 (88%)]\tLoss: 0.053471\n",
      "Actor Train Epoch: 33 [76800/80000 (96%)]\tLoss: 0.053667\n",
      "Critic Train Epoch: 33 [0/80000 (0%)]\tLoss: 93102.812500\n",
      "Critic Train Epoch: 33 [6400/80000 (8%)]\tLoss: 80865.343750\n",
      "Critic Train Epoch: 33 [12800/80000 (16%)]\tLoss: 104209.445312\n",
      "Critic Train Epoch: 33 [19200/80000 (24%)]\tLoss: 100429.515625\n",
      "Critic Train Epoch: 33 [25600/80000 (32%)]\tLoss: 101018.085938\n",
      "Critic Train Epoch: 33 [32000/80000 (40%)]\tLoss: 97128.531250\n",
      "Critic Train Epoch: 33 [38400/80000 (48%)]\tLoss: 97363.312500\n",
      "Critic Train Epoch: 33 [44800/80000 (56%)]\tLoss: 106735.882812\n",
      "Critic Train Epoch: 33 [51200/80000 (64%)]\tLoss: 92871.453125\n",
      "Critic Train Epoch: 33 [57600/80000 (72%)]\tLoss: 88782.328125\n",
      "Critic Train Epoch: 33 [64000/80000 (80%)]\tLoss: 95648.312500\n",
      "Critic Train Epoch: 33 [70400/80000 (88%)]\tLoss: 85095.039062\n",
      "Critic Train Epoch: 33 [76800/80000 (96%)]\tLoss: 97976.929688\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.8526\n",
      "Actor Train Epoch: 34 [0/80000 (0%)]\tLoss: 0.055415\n",
      "Actor Train Epoch: 34 [6400/80000 (8%)]\tLoss: 0.053999\n",
      "Actor Train Epoch: 34 [12800/80000 (16%)]\tLoss: 0.263245\n",
      "Actor Train Epoch: 34 [19200/80000 (24%)]\tLoss: 0.054144\n",
      "Actor Train Epoch: 34 [25600/80000 (32%)]\tLoss: 0.053118\n",
      "Actor Train Epoch: 34 [32000/80000 (40%)]\tLoss: 0.054552\n",
      "Actor Train Epoch: 34 [38400/80000 (48%)]\tLoss: 0.053984\n",
      "Actor Train Epoch: 34 [44800/80000 (56%)]\tLoss: 0.054161\n",
      "Actor Train Epoch: 34 [51200/80000 (64%)]\tLoss: 0.057780\n",
      "Actor Train Epoch: 34 [57600/80000 (72%)]\tLoss: 0.054635\n",
      "Actor Train Epoch: 34 [64000/80000 (80%)]\tLoss: 0.123000\n",
      "Actor Train Epoch: 34 [70400/80000 (88%)]\tLoss: 0.121188\n",
      "Actor Train Epoch: 34 [76800/80000 (96%)]\tLoss: 0.054413\n",
      "Critic Train Epoch: 34 [0/80000 (0%)]\tLoss: 91736.968750\n",
      "Critic Train Epoch: 34 [6400/80000 (8%)]\tLoss: 86185.234375\n",
      "Critic Train Epoch: 34 [12800/80000 (16%)]\tLoss: 84563.304688\n",
      "Critic Train Epoch: 34 [19200/80000 (24%)]\tLoss: 99646.171875\n",
      "Critic Train Epoch: 34 [25600/80000 (32%)]\tLoss: 91674.125000\n",
      "Critic Train Epoch: 34 [32000/80000 (40%)]\tLoss: 87823.968750\n",
      "Critic Train Epoch: 34 [38400/80000 (48%)]\tLoss: 100867.015625\n",
      "Critic Train Epoch: 34 [44800/80000 (56%)]\tLoss: 92002.632812\n",
      "Critic Train Epoch: 34 [51200/80000 (64%)]\tLoss: 100510.695312\n",
      "Critic Train Epoch: 34 [57600/80000 (72%)]\tLoss: 97445.343750\n",
      "Critic Train Epoch: 34 [64000/80000 (80%)]\tLoss: 99005.203125\n",
      "Critic Train Epoch: 34 [70400/80000 (88%)]\tLoss: 95860.101562\n",
      "Critic Train Epoch: 34 [76800/80000 (96%)]\tLoss: 92669.703125\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.8666\n",
      "Actor Train Epoch: 35 [0/80000 (0%)]\tLoss: 0.056163\n",
      "Actor Train Epoch: 35 [6400/80000 (8%)]\tLoss: 0.054738\n",
      "Actor Train Epoch: 35 [12800/80000 (16%)]\tLoss: 0.052608\n",
      "Actor Train Epoch: 35 [19200/80000 (24%)]\tLoss: 0.051594\n",
      "Actor Train Epoch: 35 [25600/80000 (32%)]\tLoss: 0.055276\n",
      "Actor Train Epoch: 35 [32000/80000 (40%)]\tLoss: 0.054283\n",
      "Actor Train Epoch: 35 [38400/80000 (48%)]\tLoss: 0.122964\n",
      "Actor Train Epoch: 35 [44800/80000 (56%)]\tLoss: 0.055329\n",
      "Actor Train Epoch: 35 [51200/80000 (64%)]\tLoss: 0.124627\n",
      "Actor Train Epoch: 35 [57600/80000 (72%)]\tLoss: 0.055715\n",
      "Actor Train Epoch: 35 [64000/80000 (80%)]\tLoss: 0.122642\n",
      "Actor Train Epoch: 35 [70400/80000 (88%)]\tLoss: 0.053354\n",
      "Actor Train Epoch: 35 [76800/80000 (96%)]\tLoss: 0.056388\n",
      "Critic Train Epoch: 35 [0/80000 (0%)]\tLoss: 101605.601562\n",
      "Critic Train Epoch: 35 [6400/80000 (8%)]\tLoss: 94306.953125\n",
      "Critic Train Epoch: 35 [12800/80000 (16%)]\tLoss: 89439.812500\n",
      "Critic Train Epoch: 35 [19200/80000 (24%)]\tLoss: 81271.343750\n",
      "Critic Train Epoch: 35 [25600/80000 (32%)]\tLoss: 92374.312500\n",
      "Critic Train Epoch: 35 [32000/80000 (40%)]\tLoss: 92328.843750\n",
      "Critic Train Epoch: 35 [38400/80000 (48%)]\tLoss: 98849.617188\n",
      "Critic Train Epoch: 35 [44800/80000 (56%)]\tLoss: 94987.742188\n",
      "Critic Train Epoch: 35 [51200/80000 (64%)]\tLoss: 93693.617188\n",
      "Critic Train Epoch: 35 [57600/80000 (72%)]\tLoss: 108668.984375\n",
      "Critic Train Epoch: 35 [64000/80000 (80%)]\tLoss: 85413.742188\n",
      "Critic Train Epoch: 35 [70400/80000 (88%)]\tLoss: 89576.445312\n",
      "Critic Train Epoch: 35 [76800/80000 (96%)]\tLoss: 91284.148438\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.8503\n",
      "Actor Train Epoch: 36 [0/80000 (0%)]\tLoss: 0.053251\n",
      "Actor Train Epoch: 36 [6400/80000 (8%)]\tLoss: 0.054390\n",
      "Actor Train Epoch: 36 [12800/80000 (16%)]\tLoss: 0.054767\n",
      "Actor Train Epoch: 36 [19200/80000 (24%)]\tLoss: 0.053612\n",
      "Actor Train Epoch: 36 [25600/80000 (32%)]\tLoss: 0.053299\n",
      "Actor Train Epoch: 36 [32000/80000 (40%)]\tLoss: 0.052609\n",
      "Actor Train Epoch: 36 [38400/80000 (48%)]\tLoss: 0.054410\n",
      "Actor Train Epoch: 36 [44800/80000 (56%)]\tLoss: 0.051084\n",
      "Actor Train Epoch: 36 [51200/80000 (64%)]\tLoss: 0.054166\n",
      "Actor Train Epoch: 36 [57600/80000 (72%)]\tLoss: 0.053755\n",
      "Actor Train Epoch: 36 [64000/80000 (80%)]\tLoss: 0.120655\n",
      "Actor Train Epoch: 36 [70400/80000 (88%)]\tLoss: 0.054896\n",
      "Actor Train Epoch: 36 [76800/80000 (96%)]\tLoss: 0.123644\n",
      "Critic Train Epoch: 36 [0/80000 (0%)]\tLoss: 98628.273438\n",
      "Critic Train Epoch: 36 [6400/80000 (8%)]\tLoss: 104629.460938\n",
      "Critic Train Epoch: 36 [12800/80000 (16%)]\tLoss: 103163.757812\n",
      "Critic Train Epoch: 36 [19200/80000 (24%)]\tLoss: 90804.429688\n",
      "Critic Train Epoch: 36 [25600/80000 (32%)]\tLoss: 94297.343750\n",
      "Critic Train Epoch: 36 [32000/80000 (40%)]\tLoss: 91364.523438\n",
      "Critic Train Epoch: 36 [38400/80000 (48%)]\tLoss: 96140.070312\n",
      "Critic Train Epoch: 36 [44800/80000 (56%)]\tLoss: 98988.640625\n",
      "Critic Train Epoch: 36 [51200/80000 (64%)]\tLoss: 96818.546875\n",
      "Critic Train Epoch: 36 [57600/80000 (72%)]\tLoss: 80385.148438\n",
      "Critic Train Epoch: 36 [64000/80000 (80%)]\tLoss: 98895.640625\n",
      "Critic Train Epoch: 36 [70400/80000 (88%)]\tLoss: 94428.968750\n",
      "Critic Train Epoch: 36 [76800/80000 (96%)]\tLoss: 98083.976562\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 2.2090\n",
      "Actor Train Epoch: 37 [0/80000 (0%)]\tLoss: 0.125680\n",
      "Actor Train Epoch: 37 [6400/80000 (8%)]\tLoss: 0.124786\n",
      "Actor Train Epoch: 37 [12800/80000 (16%)]\tLoss: 0.189156\n",
      "Actor Train Epoch: 37 [19200/80000 (24%)]\tLoss: 0.054255\n",
      "Actor Train Epoch: 37 [25600/80000 (32%)]\tLoss: 0.126368\n",
      "Actor Train Epoch: 37 [32000/80000 (40%)]\tLoss: 0.055267\n",
      "Actor Train Epoch: 37 [38400/80000 (48%)]\tLoss: 0.051797\n",
      "Actor Train Epoch: 37 [44800/80000 (56%)]\tLoss: 0.055222\n",
      "Actor Train Epoch: 37 [51200/80000 (64%)]\tLoss: 0.053888\n",
      "Actor Train Epoch: 37 [57600/80000 (72%)]\tLoss: 0.053973\n",
      "Actor Train Epoch: 37 [64000/80000 (80%)]\tLoss: 0.123075\n",
      "Actor Train Epoch: 37 [70400/80000 (88%)]\tLoss: 0.055130\n",
      "Actor Train Epoch: 37 [76800/80000 (96%)]\tLoss: 0.052867\n",
      "Critic Train Epoch: 37 [0/80000 (0%)]\tLoss: 93569.414062\n",
      "Critic Train Epoch: 37 [6400/80000 (8%)]\tLoss: 95988.289062\n",
      "Critic Train Epoch: 37 [12800/80000 (16%)]\tLoss: 87919.851562\n",
      "Critic Train Epoch: 37 [19200/80000 (24%)]\tLoss: 94704.156250\n",
      "Critic Train Epoch: 37 [25600/80000 (32%)]\tLoss: 92301.609375\n",
      "Critic Train Epoch: 37 [32000/80000 (40%)]\tLoss: 110531.171875\n",
      "Critic Train Epoch: 37 [38400/80000 (48%)]\tLoss: 86221.343750\n",
      "Critic Train Epoch: 37 [44800/80000 (56%)]\tLoss: 98388.093750\n",
      "Critic Train Epoch: 37 [51200/80000 (64%)]\tLoss: 92814.593750\n",
      "Critic Train Epoch: 37 [57600/80000 (72%)]\tLoss: 87844.687500\n",
      "Critic Train Epoch: 37 [64000/80000 (80%)]\tLoss: 89811.406250\n",
      "Critic Train Epoch: 37 [70400/80000 (88%)]\tLoss: 94578.437500\n",
      "Critic Train Epoch: 37 [76800/80000 (96%)]\tLoss: 95914.875000\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 2.2327\n",
      "Actor Train Epoch: 38 [0/80000 (0%)]\tLoss: 0.122379\n",
      "Actor Train Epoch: 38 [6400/80000 (8%)]\tLoss: 0.053419\n",
      "Actor Train Epoch: 38 [12800/80000 (16%)]\tLoss: 0.055527\n",
      "Actor Train Epoch: 38 [19200/80000 (24%)]\tLoss: 0.054759\n",
      "Actor Train Epoch: 38 [25600/80000 (32%)]\tLoss: 0.056838\n",
      "Actor Train Epoch: 38 [32000/80000 (40%)]\tLoss: 0.054207\n",
      "Actor Train Epoch: 38 [38400/80000 (48%)]\tLoss: 0.054941\n",
      "Actor Train Epoch: 38 [44800/80000 (56%)]\tLoss: 0.189307\n",
      "Actor Train Epoch: 38 [51200/80000 (64%)]\tLoss: 0.054138\n",
      "Actor Train Epoch: 38 [57600/80000 (72%)]\tLoss: 0.052675\n",
      "Actor Train Epoch: 38 [64000/80000 (80%)]\tLoss: 0.055326\n",
      "Actor Train Epoch: 38 [70400/80000 (88%)]\tLoss: 0.123602\n",
      "Actor Train Epoch: 38 [76800/80000 (96%)]\tLoss: 0.052866\n",
      "Critic Train Epoch: 38 [0/80000 (0%)]\tLoss: 89771.968750\n",
      "Critic Train Epoch: 38 [6400/80000 (8%)]\tLoss: 103650.851562\n",
      "Critic Train Epoch: 38 [12800/80000 (16%)]\tLoss: 100473.007812\n",
      "Critic Train Epoch: 38 [19200/80000 (24%)]\tLoss: 85460.851562\n",
      "Critic Train Epoch: 38 [25600/80000 (32%)]\tLoss: 104642.429688\n",
      "Critic Train Epoch: 38 [32000/80000 (40%)]\tLoss: 94958.539062\n",
      "Critic Train Epoch: 38 [38400/80000 (48%)]\tLoss: 95883.289062\n",
      "Critic Train Epoch: 38 [44800/80000 (56%)]\tLoss: 100029.695312\n",
      "Critic Train Epoch: 38 [51200/80000 (64%)]\tLoss: 95556.968750\n",
      "Critic Train Epoch: 38 [57600/80000 (72%)]\tLoss: 87112.789062\n",
      "Critic Train Epoch: 38 [64000/80000 (80%)]\tLoss: 102201.179688\n",
      "Critic Train Epoch: 38 [70400/80000 (88%)]\tLoss: 100618.781250\n",
      "Critic Train Epoch: 38 [76800/80000 (96%)]\tLoss: 88545.140625\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 2.0912\n",
      "Actor Train Epoch: 39 [0/80000 (0%)]\tLoss: 0.054446\n",
      "Actor Train Epoch: 39 [6400/80000 (8%)]\tLoss: 0.123134\n",
      "Actor Train Epoch: 39 [12800/80000 (16%)]\tLoss: 0.056221\n",
      "Actor Train Epoch: 39 [19200/80000 (24%)]\tLoss: 0.053250\n",
      "Actor Train Epoch: 39 [25600/80000 (32%)]\tLoss: 0.121447\n",
      "Actor Train Epoch: 39 [32000/80000 (40%)]\tLoss: 0.055244\n",
      "Actor Train Epoch: 39 [38400/80000 (48%)]\tLoss: 0.054929\n",
      "Actor Train Epoch: 39 [44800/80000 (56%)]\tLoss: 0.053905\n",
      "Actor Train Epoch: 39 [51200/80000 (64%)]\tLoss: 0.053412\n",
      "Actor Train Epoch: 39 [57600/80000 (72%)]\tLoss: 0.054104\n",
      "Actor Train Epoch: 39 [64000/80000 (80%)]\tLoss: 0.052214\n",
      "Actor Train Epoch: 39 [70400/80000 (88%)]\tLoss: 0.054539\n",
      "Actor Train Epoch: 39 [76800/80000 (96%)]\tLoss: 0.121604\n",
      "Critic Train Epoch: 39 [0/80000 (0%)]\tLoss: 96213.773438\n",
      "Critic Train Epoch: 39 [6400/80000 (8%)]\tLoss: 88420.453125\n",
      "Critic Train Epoch: 39 [12800/80000 (16%)]\tLoss: 89183.750000\n",
      "Critic Train Epoch: 39 [19200/80000 (24%)]\tLoss: 83449.968750\n",
      "Critic Train Epoch: 39 [25600/80000 (32%)]\tLoss: 94881.367188\n",
      "Critic Train Epoch: 39 [32000/80000 (40%)]\tLoss: 105166.914062\n",
      "Critic Train Epoch: 39 [38400/80000 (48%)]\tLoss: 96316.218750\n",
      "Critic Train Epoch: 39 [44800/80000 (56%)]\tLoss: 97033.257812\n",
      "Critic Train Epoch: 39 [51200/80000 (64%)]\tLoss: 90473.679688\n",
      "Critic Train Epoch: 39 [57600/80000 (72%)]\tLoss: 94112.171875\n",
      "Critic Train Epoch: 39 [64000/80000 (80%)]\tLoss: 101282.921875\n",
      "Critic Train Epoch: 39 [70400/80000 (88%)]\tLoss: 95188.750000\n",
      "Critic Train Epoch: 39 [76800/80000 (96%)]\tLoss: 98743.335938\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.8864\n",
      "Actor Train Epoch: 40 [0/80000 (0%)]\tLoss: 0.054776\n",
      "Actor Train Epoch: 40 [6400/80000 (8%)]\tLoss: 0.122150\n",
      "Actor Train Epoch: 40 [12800/80000 (16%)]\tLoss: 0.053903\n",
      "Actor Train Epoch: 40 [19200/80000 (24%)]\tLoss: 0.054035\n",
      "Actor Train Epoch: 40 [25600/80000 (32%)]\tLoss: 0.054282\n",
      "Actor Train Epoch: 40 [32000/80000 (40%)]\tLoss: 0.120944\n",
      "Actor Train Epoch: 40 [38400/80000 (48%)]\tLoss: 0.053738\n",
      "Actor Train Epoch: 40 [44800/80000 (56%)]\tLoss: 0.055256\n",
      "Actor Train Epoch: 40 [51200/80000 (64%)]\tLoss: 0.056159\n",
      "Actor Train Epoch: 40 [57600/80000 (72%)]\tLoss: 0.189849\n",
      "Actor Train Epoch: 40 [64000/80000 (80%)]\tLoss: 0.053866\n",
      "Actor Train Epoch: 40 [70400/80000 (88%)]\tLoss: 0.120955\n",
      "Actor Train Epoch: 40 [76800/80000 (96%)]\tLoss: 0.054464\n",
      "Critic Train Epoch: 40 [0/80000 (0%)]\tLoss: 84649.835938\n",
      "Critic Train Epoch: 40 [6400/80000 (8%)]\tLoss: 98242.468750\n",
      "Critic Train Epoch: 40 [12800/80000 (16%)]\tLoss: 98536.718750\n",
      "Critic Train Epoch: 40 [19200/80000 (24%)]\tLoss: 99268.453125\n",
      "Critic Train Epoch: 40 [25600/80000 (32%)]\tLoss: 95864.257812\n",
      "Critic Train Epoch: 40 [32000/80000 (40%)]\tLoss: 100832.117188\n",
      "Critic Train Epoch: 40 [38400/80000 (48%)]\tLoss: 111045.156250\n",
      "Critic Train Epoch: 40 [44800/80000 (56%)]\tLoss: 88384.484375\n",
      "Critic Train Epoch: 40 [51200/80000 (64%)]\tLoss: 94385.476562\n",
      "Critic Train Epoch: 40 [57600/80000 (72%)]\tLoss: 94006.492188\n",
      "Critic Train Epoch: 40 [64000/80000 (80%)]\tLoss: 103298.070312\n",
      "Critic Train Epoch: 40 [70400/80000 (88%)]\tLoss: 102102.031250\n",
      "Critic Train Epoch: 40 [76800/80000 (96%)]\tLoss: 91263.484375\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.8336\n",
      "Actor Train Epoch: 41 [0/80000 (0%)]\tLoss: 0.056850\n",
      "Actor Train Epoch: 41 [6400/80000 (8%)]\tLoss: 0.056326\n",
      "Actor Train Epoch: 41 [12800/80000 (16%)]\tLoss: 0.054939\n",
      "Actor Train Epoch: 41 [19200/80000 (24%)]\tLoss: 0.052630\n",
      "Actor Train Epoch: 41 [25600/80000 (32%)]\tLoss: 0.053461\n",
      "Actor Train Epoch: 41 [32000/80000 (40%)]\tLoss: 0.056641\n",
      "Actor Train Epoch: 41 [38400/80000 (48%)]\tLoss: 0.054914\n",
      "Actor Train Epoch: 41 [44800/80000 (56%)]\tLoss: 0.051849\n",
      "Actor Train Epoch: 41 [51200/80000 (64%)]\tLoss: 0.054370\n",
      "Actor Train Epoch: 41 [57600/80000 (72%)]\tLoss: 0.123501\n",
      "Actor Train Epoch: 41 [64000/80000 (80%)]\tLoss: 0.123900\n",
      "Actor Train Epoch: 41 [70400/80000 (88%)]\tLoss: 0.055718\n",
      "Actor Train Epoch: 41 [76800/80000 (96%)]\tLoss: 0.054838\n",
      "Critic Train Epoch: 41 [0/80000 (0%)]\tLoss: 91060.390625\n",
      "Critic Train Epoch: 41 [6400/80000 (8%)]\tLoss: 101025.375000\n",
      "Critic Train Epoch: 41 [12800/80000 (16%)]\tLoss: 100680.367188\n",
      "Critic Train Epoch: 41 [19200/80000 (24%)]\tLoss: 85694.031250\n",
      "Critic Train Epoch: 41 [25600/80000 (32%)]\tLoss: 108687.812500\n",
      "Critic Train Epoch: 41 [32000/80000 (40%)]\tLoss: 90998.046875\n",
      "Critic Train Epoch: 41 [38400/80000 (48%)]\tLoss: 103686.664062\n",
      "Critic Train Epoch: 41 [44800/80000 (56%)]\tLoss: 89731.062500\n",
      "Critic Train Epoch: 41 [51200/80000 (64%)]\tLoss: 98136.867188\n",
      "Critic Train Epoch: 41 [57600/80000 (72%)]\tLoss: 93627.257812\n",
      "Critic Train Epoch: 41 [64000/80000 (80%)]\tLoss: 113687.289062\n",
      "Critic Train Epoch: 41 [70400/80000 (88%)]\tLoss: 119995.320312\n",
      "Critic Train Epoch: 41 [76800/80000 (96%)]\tLoss: 95872.351562\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 2.1717\n",
      "Actor Train Epoch: 42 [0/80000 (0%)]\tLoss: 0.053721\n",
      "Actor Train Epoch: 42 [6400/80000 (8%)]\tLoss: 0.051874\n",
      "Actor Train Epoch: 42 [12800/80000 (16%)]\tLoss: 0.123382\n",
      "Actor Train Epoch: 42 [19200/80000 (24%)]\tLoss: 0.054150\n",
      "Actor Train Epoch: 42 [25600/80000 (32%)]\tLoss: 0.054807\n",
      "Actor Train Epoch: 42 [32000/80000 (40%)]\tLoss: 0.053324\n",
      "Actor Train Epoch: 42 [38400/80000 (48%)]\tLoss: 0.121679\n",
      "Actor Train Epoch: 42 [44800/80000 (56%)]\tLoss: 0.125333\n",
      "Actor Train Epoch: 42 [51200/80000 (64%)]\tLoss: 0.051982\n",
      "Actor Train Epoch: 42 [57600/80000 (72%)]\tLoss: 0.054185\n",
      "Actor Train Epoch: 42 [64000/80000 (80%)]\tLoss: 0.054093\n",
      "Actor Train Epoch: 42 [70400/80000 (88%)]\tLoss: 0.054592\n",
      "Actor Train Epoch: 42 [76800/80000 (96%)]\tLoss: 0.053117\n",
      "Critic Train Epoch: 42 [0/80000 (0%)]\tLoss: 90349.750000\n",
      "Critic Train Epoch: 42 [6400/80000 (8%)]\tLoss: 111576.992188\n",
      "Critic Train Epoch: 42 [12800/80000 (16%)]\tLoss: 92980.125000\n",
      "Critic Train Epoch: 42 [19200/80000 (24%)]\tLoss: 116213.093750\n",
      "Critic Train Epoch: 42 [25600/80000 (32%)]\tLoss: 85558.945312\n",
      "Critic Train Epoch: 42 [32000/80000 (40%)]\tLoss: 109091.945312\n",
      "Critic Train Epoch: 42 [38400/80000 (48%)]\tLoss: 102499.382812\n",
      "Critic Train Epoch: 42 [44800/80000 (56%)]\tLoss: 96487.523438\n",
      "Critic Train Epoch: 42 [51200/80000 (64%)]\tLoss: 87563.867188\n",
      "Critic Train Epoch: 42 [57600/80000 (72%)]\tLoss: 93788.960938\n",
      "Critic Train Epoch: 42 [64000/80000 (80%)]\tLoss: 111183.968750\n",
      "Critic Train Epoch: 42 [70400/80000 (88%)]\tLoss: 101977.031250\n",
      "Critic Train Epoch: 42 [76800/80000 (96%)]\tLoss: 96328.164062\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 2.1386\n",
      "Actor Train Epoch: 43 [0/80000 (0%)]\tLoss: 0.051292\n",
      "Actor Train Epoch: 43 [6400/80000 (8%)]\tLoss: 0.054298\n",
      "Actor Train Epoch: 43 [12800/80000 (16%)]\tLoss: 0.121756\n",
      "Actor Train Epoch: 43 [19200/80000 (24%)]\tLoss: 0.121721\n",
      "Actor Train Epoch: 43 [25600/80000 (32%)]\tLoss: 0.055406\n",
      "Actor Train Epoch: 43 [32000/80000 (40%)]\tLoss: 0.052510\n",
      "Actor Train Epoch: 43 [38400/80000 (48%)]\tLoss: 0.121248\n",
      "Actor Train Epoch: 43 [44800/80000 (56%)]\tLoss: 0.053089\n",
      "Actor Train Epoch: 43 [51200/80000 (64%)]\tLoss: 0.054987\n",
      "Actor Train Epoch: 43 [57600/80000 (72%)]\tLoss: 0.054189\n",
      "Actor Train Epoch: 43 [64000/80000 (80%)]\tLoss: 0.054669\n",
      "Actor Train Epoch: 43 [70400/80000 (88%)]\tLoss: 0.054522\n",
      "Actor Train Epoch: 43 [76800/80000 (96%)]\tLoss: 0.191189\n",
      "Critic Train Epoch: 43 [0/80000 (0%)]\tLoss: 92812.226562\n",
      "Critic Train Epoch: 43 [6400/80000 (8%)]\tLoss: 89224.312500\n",
      "Critic Train Epoch: 43 [12800/80000 (16%)]\tLoss: 85650.125000\n",
      "Critic Train Epoch: 43 [19200/80000 (24%)]\tLoss: 99554.804688\n",
      "Critic Train Epoch: 43 [25600/80000 (32%)]\tLoss: 100197.882812\n",
      "Critic Train Epoch: 43 [32000/80000 (40%)]\tLoss: 88282.367188\n",
      "Critic Train Epoch: 43 [38400/80000 (48%)]\tLoss: 99326.281250\n",
      "Critic Train Epoch: 43 [44800/80000 (56%)]\tLoss: 103658.656250\n",
      "Critic Train Epoch: 43 [51200/80000 (64%)]\tLoss: 101458.445312\n",
      "Critic Train Epoch: 43 [57600/80000 (72%)]\tLoss: 108099.195312\n",
      "Critic Train Epoch: 43 [64000/80000 (80%)]\tLoss: 95077.187500\n",
      "Critic Train Epoch: 43 [70400/80000 (88%)]\tLoss: 105683.703125\n",
      "Critic Train Epoch: 43 [76800/80000 (96%)]\tLoss: 91266.531250\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.9423\n",
      "Actor Train Epoch: 44 [0/80000 (0%)]\tLoss: 0.052953\n",
      "Actor Train Epoch: 44 [6400/80000 (8%)]\tLoss: 0.052688\n",
      "Actor Train Epoch: 44 [12800/80000 (16%)]\tLoss: 0.054753\n",
      "Actor Train Epoch: 44 [19200/80000 (24%)]\tLoss: 0.054398\n",
      "Actor Train Epoch: 44 [25600/80000 (32%)]\tLoss: 0.055984\n",
      "Actor Train Epoch: 44 [32000/80000 (40%)]\tLoss: 0.055355\n",
      "Actor Train Epoch: 44 [38400/80000 (48%)]\tLoss: 0.052761\n",
      "Actor Train Epoch: 44 [44800/80000 (56%)]\tLoss: 0.122987\n",
      "Actor Train Epoch: 44 [51200/80000 (64%)]\tLoss: 0.055540\n",
      "Actor Train Epoch: 44 [57600/80000 (72%)]\tLoss: 0.123722\n",
      "Actor Train Epoch: 44 [64000/80000 (80%)]\tLoss: 0.054421\n",
      "Actor Train Epoch: 44 [70400/80000 (88%)]\tLoss: 0.055142\n",
      "Actor Train Epoch: 44 [76800/80000 (96%)]\tLoss: 0.053602\n",
      "Critic Train Epoch: 44 [0/80000 (0%)]\tLoss: 113994.781250\n",
      "Critic Train Epoch: 44 [6400/80000 (8%)]\tLoss: 87728.664062\n",
      "Critic Train Epoch: 44 [12800/80000 (16%)]\tLoss: 86837.515625\n",
      "Critic Train Epoch: 44 [19200/80000 (24%)]\tLoss: 102039.492188\n",
      "Critic Train Epoch: 44 [25600/80000 (32%)]\tLoss: 83558.601562\n",
      "Critic Train Epoch: 44 [32000/80000 (40%)]\tLoss: 88536.468750\n",
      "Critic Train Epoch: 44 [38400/80000 (48%)]\tLoss: 92581.531250\n",
      "Critic Train Epoch: 44 [44800/80000 (56%)]\tLoss: 89257.929688\n",
      "Critic Train Epoch: 44 [51200/80000 (64%)]\tLoss: 99794.484375\n",
      "Critic Train Epoch: 44 [57600/80000 (72%)]\tLoss: 106412.375000\n",
      "Critic Train Epoch: 44 [64000/80000 (80%)]\tLoss: 98941.164062\n",
      "Critic Train Epoch: 44 [70400/80000 (88%)]\tLoss: 92820.406250\n",
      "Critic Train Epoch: 44 [76800/80000 (96%)]\tLoss: 108947.390625\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.9045\n",
      "Actor Train Epoch: 45 [0/80000 (0%)]\tLoss: 0.057318\n",
      "Actor Train Epoch: 45 [6400/80000 (8%)]\tLoss: 0.054049\n",
      "Actor Train Epoch: 45 [12800/80000 (16%)]\tLoss: 0.054682\n",
      "Actor Train Epoch: 45 [19200/80000 (24%)]\tLoss: 0.055000\n",
      "Actor Train Epoch: 45 [25600/80000 (32%)]\tLoss: 0.054017\n",
      "Actor Train Epoch: 45 [32000/80000 (40%)]\tLoss: 0.055762\n",
      "Actor Train Epoch: 45 [38400/80000 (48%)]\tLoss: 0.053578\n",
      "Actor Train Epoch: 45 [44800/80000 (56%)]\tLoss: 0.122587\n",
      "Actor Train Epoch: 45 [51200/80000 (64%)]\tLoss: 0.054783\n",
      "Actor Train Epoch: 45 [57600/80000 (72%)]\tLoss: 0.055025\n",
      "Actor Train Epoch: 45 [64000/80000 (80%)]\tLoss: 0.054792\n",
      "Actor Train Epoch: 45 [70400/80000 (88%)]\tLoss: 0.053068\n",
      "Actor Train Epoch: 45 [76800/80000 (96%)]\tLoss: 0.054735\n",
      "Critic Train Epoch: 45 [0/80000 (0%)]\tLoss: 100181.851562\n",
      "Critic Train Epoch: 45 [6400/80000 (8%)]\tLoss: 97554.921875\n",
      "Critic Train Epoch: 45 [12800/80000 (16%)]\tLoss: 99548.421875\n",
      "Critic Train Epoch: 45 [19200/80000 (24%)]\tLoss: 87604.812500\n",
      "Critic Train Epoch: 45 [25600/80000 (32%)]\tLoss: 94848.921875\n",
      "Critic Train Epoch: 45 [32000/80000 (40%)]\tLoss: 90082.632812\n",
      "Critic Train Epoch: 45 [38400/80000 (48%)]\tLoss: 86714.421875\n",
      "Critic Train Epoch: 45 [44800/80000 (56%)]\tLoss: 94901.132812\n",
      "Critic Train Epoch: 45 [51200/80000 (64%)]\tLoss: 96209.976562\n",
      "Critic Train Epoch: 45 [57600/80000 (72%)]\tLoss: 100455.125000\n",
      "Critic Train Epoch: 45 [64000/80000 (80%)]\tLoss: 110534.679688\n",
      "Critic Train Epoch: 45 [70400/80000 (88%)]\tLoss: 101104.515625\n",
      "Critic Train Epoch: 45 [76800/80000 (96%)]\tLoss: 90300.875000\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.8056\n",
      "Actor Train Epoch: 46 [0/80000 (0%)]\tLoss: 0.055793\n",
      "Actor Train Epoch: 46 [6400/80000 (8%)]\tLoss: 0.052189\n",
      "Actor Train Epoch: 46 [12800/80000 (16%)]\tLoss: 0.053888\n",
      "Actor Train Epoch: 46 [19200/80000 (24%)]\tLoss: 0.053033\n",
      "Actor Train Epoch: 46 [25600/80000 (32%)]\tLoss: 0.121269\n",
      "Actor Train Epoch: 46 [32000/80000 (40%)]\tLoss: 0.052947\n",
      "Actor Train Epoch: 46 [38400/80000 (48%)]\tLoss: 0.053975\n",
      "Actor Train Epoch: 46 [44800/80000 (56%)]\tLoss: 0.052702\n",
      "Actor Train Epoch: 46 [51200/80000 (64%)]\tLoss: 0.054787\n",
      "Actor Train Epoch: 46 [57600/80000 (72%)]\tLoss: 0.054186\n",
      "Actor Train Epoch: 46 [64000/80000 (80%)]\tLoss: 0.122807\n",
      "Actor Train Epoch: 46 [70400/80000 (88%)]\tLoss: 0.053766\n",
      "Actor Train Epoch: 46 [76800/80000 (96%)]\tLoss: 0.058496\n",
      "Critic Train Epoch: 46 [0/80000 (0%)]\tLoss: 97445.507812\n",
      "Critic Train Epoch: 46 [6400/80000 (8%)]\tLoss: 95275.945312\n",
      "Critic Train Epoch: 46 [12800/80000 (16%)]\tLoss: 93689.843750\n",
      "Critic Train Epoch: 46 [19200/80000 (24%)]\tLoss: 96258.109375\n",
      "Critic Train Epoch: 46 [25600/80000 (32%)]\tLoss: 104396.875000\n",
      "Critic Train Epoch: 46 [32000/80000 (40%)]\tLoss: 90407.812500\n",
      "Critic Train Epoch: 46 [38400/80000 (48%)]\tLoss: 110987.750000\n",
      "Critic Train Epoch: 46 [44800/80000 (56%)]\tLoss: 89017.078125\n",
      "Critic Train Epoch: 46 [51200/80000 (64%)]\tLoss: 83635.914062\n",
      "Critic Train Epoch: 46 [57600/80000 (72%)]\tLoss: 91446.296875\n",
      "Critic Train Epoch: 46 [64000/80000 (80%)]\tLoss: 92273.507812\n",
      "Critic Train Epoch: 46 [70400/80000 (88%)]\tLoss: 97456.968750\n",
      "Critic Train Epoch: 46 [76800/80000 (96%)]\tLoss: 96226.015625\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 2.3321\n",
      "Actor Train Epoch: 47 [0/80000 (0%)]\tLoss: 0.052548\n",
      "Actor Train Epoch: 47 [6400/80000 (8%)]\tLoss: 0.055104\n",
      "Actor Train Epoch: 47 [12800/80000 (16%)]\tLoss: 0.053531\n",
      "Actor Train Epoch: 47 [19200/80000 (24%)]\tLoss: 0.055221\n",
      "Actor Train Epoch: 47 [25600/80000 (32%)]\tLoss: 0.056248\n",
      "Actor Train Epoch: 47 [32000/80000 (40%)]\tLoss: 0.054604\n",
      "Actor Train Epoch: 47 [38400/80000 (48%)]\tLoss: 0.053553\n",
      "Actor Train Epoch: 47 [44800/80000 (56%)]\tLoss: 0.055915\n",
      "Actor Train Epoch: 47 [51200/80000 (64%)]\tLoss: 0.121463\n",
      "Actor Train Epoch: 47 [57600/80000 (72%)]\tLoss: 0.121245\n",
      "Actor Train Epoch: 47 [64000/80000 (80%)]\tLoss: 0.054861\n",
      "Actor Train Epoch: 47 [70400/80000 (88%)]\tLoss: 0.122511\n",
      "Actor Train Epoch: 47 [76800/80000 (96%)]\tLoss: 0.054002\n",
      "Critic Train Epoch: 47 [0/80000 (0%)]\tLoss: 92232.867188\n",
      "Critic Train Epoch: 47 [6400/80000 (8%)]\tLoss: 106485.210938\n",
      "Critic Train Epoch: 47 [12800/80000 (16%)]\tLoss: 103479.890625\n",
      "Critic Train Epoch: 47 [19200/80000 (24%)]\tLoss: 91691.296875\n",
      "Critic Train Epoch: 47 [25600/80000 (32%)]\tLoss: 98334.812500\n",
      "Critic Train Epoch: 47 [32000/80000 (40%)]\tLoss: 92588.390625\n",
      "Critic Train Epoch: 47 [38400/80000 (48%)]\tLoss: 100650.421875\n",
      "Critic Train Epoch: 47 [44800/80000 (56%)]\tLoss: 92565.250000\n",
      "Critic Train Epoch: 47 [51200/80000 (64%)]\tLoss: 97864.187500\n",
      "Critic Train Epoch: 47 [57600/80000 (72%)]\tLoss: 97818.492188\n",
      "Critic Train Epoch: 47 [64000/80000 (80%)]\tLoss: 87254.828125\n",
      "Critic Train Epoch: 47 [70400/80000 (88%)]\tLoss: 97648.179688\n",
      "Critic Train Epoch: 47 [76800/80000 (96%)]\tLoss: 110331.945312\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.7121\n",
      "Actor Train Epoch: 48 [0/80000 (0%)]\tLoss: 0.054452\n",
      "Actor Train Epoch: 48 [6400/80000 (8%)]\tLoss: 0.054222\n",
      "Actor Train Epoch: 48 [12800/80000 (16%)]\tLoss: 0.121994\n",
      "Actor Train Epoch: 48 [19200/80000 (24%)]\tLoss: 0.120833\n",
      "Actor Train Epoch: 48 [25600/80000 (32%)]\tLoss: 0.053757\n",
      "Actor Train Epoch: 48 [32000/80000 (40%)]\tLoss: 0.258115\n",
      "Actor Train Epoch: 48 [38400/80000 (48%)]\tLoss: 0.124549\n",
      "Actor Train Epoch: 48 [44800/80000 (56%)]\tLoss: 0.190957\n",
      "Actor Train Epoch: 48 [51200/80000 (64%)]\tLoss: 0.054277\n",
      "Actor Train Epoch: 48 [57600/80000 (72%)]\tLoss: 0.058114\n",
      "Actor Train Epoch: 48 [64000/80000 (80%)]\tLoss: 0.053272\n",
      "Actor Train Epoch: 48 [70400/80000 (88%)]\tLoss: 0.123548\n",
      "Actor Train Epoch: 48 [76800/80000 (96%)]\tLoss: 0.055225\n",
      "Critic Train Epoch: 48 [0/80000 (0%)]\tLoss: 102955.078125\n",
      "Critic Train Epoch: 48 [6400/80000 (8%)]\tLoss: 96956.437500\n",
      "Critic Train Epoch: 48 [12800/80000 (16%)]\tLoss: 87722.921875\n",
      "Critic Train Epoch: 48 [19200/80000 (24%)]\tLoss: 109722.093750\n",
      "Critic Train Epoch: 48 [25600/80000 (32%)]\tLoss: 99623.843750\n",
      "Critic Train Epoch: 48 [32000/80000 (40%)]\tLoss: 89750.367188\n",
      "Critic Train Epoch: 48 [38400/80000 (48%)]\tLoss: 85689.578125\n",
      "Critic Train Epoch: 48 [44800/80000 (56%)]\tLoss: 98437.187500\n",
      "Critic Train Epoch: 48 [51200/80000 (64%)]\tLoss: 98154.382812\n",
      "Critic Train Epoch: 48 [57600/80000 (72%)]\tLoss: 107115.843750\n",
      "Critic Train Epoch: 48 [64000/80000 (80%)]\tLoss: 94707.476562\n",
      "Critic Train Epoch: 48 [70400/80000 (88%)]\tLoss: 81546.773438\n",
      "Critic Train Epoch: 48 [76800/80000 (96%)]\tLoss: 97329.992188\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 1.8039\n",
      "Actor Train Epoch: 49 [0/80000 (0%)]\tLoss: 0.055259\n",
      "Actor Train Epoch: 49 [6400/80000 (8%)]\tLoss: 0.124758\n",
      "Actor Train Epoch: 49 [12800/80000 (16%)]\tLoss: 0.057281\n",
      "Actor Train Epoch: 49 [19200/80000 (24%)]\tLoss: 0.055630\n",
      "Actor Train Epoch: 49 [25600/80000 (32%)]\tLoss: 0.054770\n",
      "Actor Train Epoch: 49 [32000/80000 (40%)]\tLoss: 0.053432\n",
      "Actor Train Epoch: 49 [38400/80000 (48%)]\tLoss: 0.054451\n",
      "Actor Train Epoch: 49 [44800/80000 (56%)]\tLoss: 0.053662\n",
      "Actor Train Epoch: 49 [51200/80000 (64%)]\tLoss: 0.055747\n",
      "Actor Train Epoch: 49 [57600/80000 (72%)]\tLoss: 0.054688\n",
      "Actor Train Epoch: 49 [64000/80000 (80%)]\tLoss: 0.052305\n",
      "Actor Train Epoch: 49 [70400/80000 (88%)]\tLoss: 0.190554\n",
      "Actor Train Epoch: 49 [76800/80000 (96%)]\tLoss: 0.052944\n",
      "Critic Train Epoch: 49 [0/80000 (0%)]\tLoss: 96186.171875\n",
      "Critic Train Epoch: 49 [6400/80000 (8%)]\tLoss: 95140.515625\n",
      "Critic Train Epoch: 49 [12800/80000 (16%)]\tLoss: 77995.109375\n",
      "Critic Train Epoch: 49 [19200/80000 (24%)]\tLoss: 109603.328125\n",
      "Critic Train Epoch: 49 [25600/80000 (32%)]\tLoss: 96828.281250\n",
      "Critic Train Epoch: 49 [32000/80000 (40%)]\tLoss: 92391.812500\n",
      "Critic Train Epoch: 49 [38400/80000 (48%)]\tLoss: 101277.593750\n",
      "Critic Train Epoch: 49 [44800/80000 (56%)]\tLoss: 99355.882812\n",
      "Critic Train Epoch: 49 [51200/80000 (64%)]\tLoss: 96528.960938\n",
      "Critic Train Epoch: 49 [57600/80000 (72%)]\tLoss: 102383.648438\n",
      "Critic Train Epoch: 49 [64000/80000 (80%)]\tLoss: 92567.632812\n",
      "Critic Train Epoch: 49 [70400/80000 (88%)]\tLoss: 95132.789062\n",
      "Critic Train Epoch: 49 [76800/80000 (96%)]\tLoss: 82663.382812\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 2.0195\n",
      "Actor Train Epoch: 50 [0/80000 (0%)]\tLoss: 0.052861\n",
      "Actor Train Epoch: 50 [6400/80000 (8%)]\tLoss: 0.053150\n",
      "Actor Train Epoch: 50 [12800/80000 (16%)]\tLoss: 0.121123\n",
      "Actor Train Epoch: 50 [19200/80000 (24%)]\tLoss: 0.122828\n",
      "Actor Train Epoch: 50 [25600/80000 (32%)]\tLoss: 0.054350\n",
      "Actor Train Epoch: 50 [32000/80000 (40%)]\tLoss: 0.053729\n",
      "Actor Train Epoch: 50 [38400/80000 (48%)]\tLoss: 0.121916\n",
      "Actor Train Epoch: 50 [44800/80000 (56%)]\tLoss: 0.119726\n",
      "Actor Train Epoch: 50 [51200/80000 (64%)]\tLoss: 0.052119\n",
      "Actor Train Epoch: 50 [57600/80000 (72%)]\tLoss: 0.054423\n",
      "Actor Train Epoch: 50 [64000/80000 (80%)]\tLoss: 0.054867\n",
      "Actor Train Epoch: 50 [70400/80000 (88%)]\tLoss: 0.055504\n",
      "Actor Train Epoch: 50 [76800/80000 (96%)]\tLoss: 0.057831\n",
      "Critic Train Epoch: 50 [0/80000 (0%)]\tLoss: 93589.953125\n",
      "Critic Train Epoch: 50 [6400/80000 (8%)]\tLoss: 92557.851562\n",
      "Critic Train Epoch: 50 [12800/80000 (16%)]\tLoss: 89451.593750\n",
      "Critic Train Epoch: 50 [19200/80000 (24%)]\tLoss: 118981.593750\n",
      "Critic Train Epoch: 50 [25600/80000 (32%)]\tLoss: 98165.343750\n",
      "Critic Train Epoch: 50 [32000/80000 (40%)]\tLoss: 108689.281250\n",
      "Critic Train Epoch: 50 [38400/80000 (48%)]\tLoss: 93778.750000\n",
      "Critic Train Epoch: 50 [44800/80000 (56%)]\tLoss: 95879.671875\n",
      "Critic Train Epoch: 50 [51200/80000 (64%)]\tLoss: 88680.976562\n",
      "Critic Train Epoch: 50 [57600/80000 (72%)]\tLoss: 94781.289062\n",
      "Critic Train Epoch: 50 [64000/80000 (80%)]\tLoss: 104429.070312\n",
      "Critic Train Epoch: 50 [70400/80000 (88%)]\tLoss: 93009.632812\n",
      "Critic Train Epoch: 50 [76800/80000 (96%)]\tLoss: 86763.523438\n",
      "Test set actor: Average loss: 0.0000\n",
      "Test set critic: Average loss: 2.0607\n"
     ]
    }
   ],
   "source": [
    "pretrain_agent(ppo_student_ws, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward = 98.45445863606326 +/- 15.295892413796253\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(ppo_student_ws, env, n_eval_episodes=1000)\n",
    "\n",
    "print(f\"Mean reward = {mean_reward} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ws\\PPO_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 157      |\n",
      "|    ep_rew_mean     | 287      |\n",
      "| time/              |          |\n",
      "|    fps             | 283      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 164         |\n",
      "|    ep_rew_mean          | 294         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000982789 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.332      |\n",
      "|    explained_variance   | 0.00473     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 7.06e+03    |\n",
      "|    n_updates            | 15          |\n",
      "|    policy_gradient_loss | -0.00284    |\n",
      "|    value_loss           | 8.07e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 171          |\n",
      "|    ep_rew_mean          | 256          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 290          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010072731 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.324       |\n",
      "|    explained_variance   | 0.0133       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.73e+03     |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    value_loss           | 7.48e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 178          |\n",
      "|    ep_rew_mean          | 277          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 293          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006794719 |\n",
      "|    clip_fraction        | 0.00905      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.314       |\n",
      "|    explained_variance   | 0.0199       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 30.3         |\n",
      "|    n_updates            | 45           |\n",
      "|    policy_gradient_loss | -0.00121     |\n",
      "|    value_loss           | 2.22e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 175          |\n",
      "|    ep_rew_mean          | 286          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 293          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005381268 |\n",
      "|    clip_fraction        | 0.00697      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.334       |\n",
      "|    explained_variance   | 0.0144       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.46e+03     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    value_loss           | 6.68e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 174        |\n",
      "|    ep_rew_mean          | 294        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 295        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 41         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00134389 |\n",
      "|    clip_fraction        | 0.0132     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.33      |\n",
      "|    explained_variance   | 0.0164     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 749        |\n",
      "|    n_updates            | 75         |\n",
      "|    policy_gradient_loss | -0.00227   |\n",
      "|    value_loss           | 7.08e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 175          |\n",
      "|    ep_rew_mean          | 311          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 298          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006229219 |\n",
      "|    clip_fraction        | 0.00299      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.334       |\n",
      "|    explained_variance   | 0.0214       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    value_loss           | 6.96e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 176          |\n",
      "|    ep_rew_mean          | 313          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 300          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010237672 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.337       |\n",
      "|    explained_variance   | 0.025        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.44e+03     |\n",
      "|    n_updates            | 105          |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    value_loss           | 8.16e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 174         |\n",
      "|    ep_rew_mean          | 312         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 300         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007064563 |\n",
      "|    clip_fraction        | 0.0243      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.391      |\n",
      "|    explained_variance   | 0.0235      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.77e+03    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00279    |\n",
      "|    value_loss           | 6.71e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 171         |\n",
      "|    ep_rew_mean          | 309         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003997938 |\n",
      "|    clip_fraction        | 0.0209      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.509      |\n",
      "|    explained_variance   | 0.0374      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 4.14e+03    |\n",
      "|    n_updates            | 135         |\n",
      "|    policy_gradient_loss | -0.00344    |\n",
      "|    value_loss           | 6.12e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 157         |\n",
      "|    ep_rew_mean          | 295         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 300         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006856436 |\n",
      "|    clip_fraction        | 0.0483      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.579      |\n",
      "|    explained_variance   | 0.0567      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 598         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    value_loss           | 3.68e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 133          |\n",
      "|    ep_rew_mean          | 238          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 301          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 81           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020063738 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.585       |\n",
      "|    explained_variance   | 0.068        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.55e+03     |\n",
      "|    n_updates            | 165          |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    value_loss           | 3.09e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 126         |\n",
      "|    ep_rew_mean          | 204         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005349774 |\n",
      "|    clip_fraction        | 0.0376      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.701      |\n",
      "|    explained_variance   | 0.228       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 411         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00267    |\n",
      "|    value_loss           | 927         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 104          |\n",
      "|    ep_rew_mean          | 151          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 302          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 94           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072022974 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.695       |\n",
      "|    explained_variance   | 0.0642       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 702          |\n",
      "|    n_updates            | 195          |\n",
      "|    policy_gradient_loss | -0.00163     |\n",
      "|    value_loss           | 4.14e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 89.2        |\n",
      "|    ep_rew_mean          | 135         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010535943 |\n",
      "|    clip_fraction        | 0.0626      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.824      |\n",
      "|    explained_variance   | 0.0895      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.07e+03    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00248    |\n",
      "|    value_loss           | 3.35e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 79.2         |\n",
      "|    ep_rew_mean          | 118          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 304          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 107          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073770476 |\n",
      "|    clip_fraction        | 0.0556       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.954       |\n",
      "|    explained_variance   | 0.0793       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 5.07e+03     |\n",
      "|    n_updates            | 225          |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    value_loss           | 6.46e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 72         |\n",
      "|    ep_rew_mean          | 128        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 304        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 114        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00404831 |\n",
      "|    clip_fraction        | 0.0109     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.962     |\n",
      "|    explained_variance   | 0.23       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 552        |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.00194   |\n",
      "|    value_loss           | 1.55e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 64.2         |\n",
      "|    ep_rew_mean          | 114          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 304          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 120          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036312118 |\n",
      "|    clip_fraction        | 0.00726      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.912       |\n",
      "|    explained_variance   | 0.0693       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.65e+03     |\n",
      "|    n_updates            | 255          |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    value_loss           | 1.01e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.7         |\n",
      "|    ep_rew_mean          | 114          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 305          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 127          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029270132 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.911       |\n",
      "|    explained_variance   | 0.14         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.86e+03     |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00172     |\n",
      "|    value_loss           | 4.95e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.8         |\n",
      "|    ep_rew_mean          | 112          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 305          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 133          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034210677 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.82        |\n",
      "|    explained_variance   | 0.118        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 192          |\n",
      "|    n_updates            | 285          |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    value_loss           | 4.27e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70.1        |\n",
      "|    ep_rew_mean          | 117         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002224292 |\n",
      "|    clip_fraction        | 0.00632     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.795      |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.62e+03    |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00255    |\n",
      "|    value_loss           | 5.81e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78           |\n",
      "|    ep_rew_mean          | 129          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 306          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 146          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044375136 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.873       |\n",
      "|    explained_variance   | 0.134        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 7.56e+03     |\n",
      "|    n_updates            | 315          |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    value_loss           | 3.91e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 92.8         |\n",
      "|    ep_rew_mean          | 153          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 307          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 153          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023532456 |\n",
      "|    clip_fraction        | 0.00729      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.886       |\n",
      "|    explained_variance   | 0.191        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 598          |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 94.5         |\n",
      "|    ep_rew_mean          | 144          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 307          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 159          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042098006 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.95        |\n",
      "|    explained_variance   | 0.152        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 4.98e+03     |\n",
      "|    n_updates            | 345          |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    value_loss           | 3.02e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 105          |\n",
      "|    ep_rew_mean          | 167          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 306          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 166          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023639412 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.958       |\n",
      "|    explained_variance   | 0.196        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 72           |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    value_loss           | 2.62e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1ce7b4a9660>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo_student_ws.learn(total_timesteps=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ppo_student_ws' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate_policy\n\u001b[1;32m----> 5\u001b[0m mean_reward, std_reward \u001b[38;5;241m=\u001b[39m evaluate_policy(\u001b[43mppo_student_ws\u001b[49m, env, n_eval_episodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean reward = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_reward\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m +/- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstd_reward\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ppo_student_ws' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(ppo_student_ws, env, n_eval_episodes=100)\n",
    "\n",
    "print(f\"Mean reward = {mean_reward} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "obs, _ = env.reset()\n",
    "\n",
    "list_dqn = []\n",
    "\n",
    "for _ in range (10):\n",
    "    done = False\n",
    "    obs, _ = env.reset()\n",
    "    #print(obs)\n",
    "\n",
    "    while not done:\n",
    "        action, _ = ppo_student_ws.predict(obs)\n",
    "\n",
    "        #print(obs)\n",
    "        #print(\"Action: \", action)\n",
    "        \n",
    "        new_obs, reward, done, _, _ = env.step(action) \n",
    "        harvest = obs[11] * obs[10]\n",
    "        \n",
    "        obs = new_obs\n",
    "    print(reward)\n",
    "    print(harvest)\n",
    "    #print(\"End\")\n",
    "    #print(obs)\n",
    "    if(obs[7]==11):\n",
    "        list_dqn.append(harvest)\n",
    "        #print(\"Final yield: \", harvest)\n",
    "    else:\n",
    "        list_dqn.append(0)\n",
    "        #print(\"Plant died\")\n",
    "\n",
    "print(\"DQN: {} +/- {}\".format(np.mean(list_dqn), np.std(list_dqn)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
